{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit (conda)",
   "display_name": "Python 3.7.6 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "be616a5aca28d3db9b0a9b4d7f249131c3d6f9e1a336d502c86d6e4c207752b0"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Chapter 20. 신경망"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 20.0 소개\n",
    "* 신경망의 핵심은 유닛(노드, 뉴런) 이다.\n",
    "    * 유닛 : 하나 이상의 입력을 받아 각 입력에 파라미터(가중치)를 곱한다.\n",
    "    * 가중치가 곱해진 입력에 어떤 bias 값(0)을 더하고 활성화 함수에 이를 전달한다.\n",
    "    * 출력은 신경망에서 만약 있다면 더 깊은 층에 있는 다른 뉴런을 위해 앞으로 전달한다.\n",
    "* 피드포워드 신경망 혹은 다층 퍼셉트론 : 다양한 실전 환경에서 사용되는 가장 간단한 인공 신경망이다.\n",
    "    * 신경망이 일련의 연결된 층으로 표현할 수 있고, 한쪽 끝에는 샘플의 특성값과 다른 한쪽에는 타깃값을 연결한 네트워크 이다.\n",
    "    * 피드포워드 : 샘플의 특성값이 네트워크 앞쪽으로 주입된다는 사실에서 착안한다.\n",
    "    * 각 층은 연속적으로 특성값을 변환하여 타깃값과 같은 최종 출력을 내는 게 목적이다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* 피드 포워드 신경망 : 입력층(input layer), 출력층(output layer), 은닉층(hidden layer)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 20.1 신경망을 위한 데이터 전처리하기\n",
    "* StandardScaler로 특성을 표준화한다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-1.12541308,  1.96429418],\n",
       "       [-1.15329466, -0.50068741],\n",
       "       [ 0.29529406, -0.22809346],\n",
       "       [ 0.57385917, -0.42335076],\n",
       "       [ 1.40955451, -0.81216255]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "features = np.array([[-100.1, 3240.1],\n",
    "                    [-200.2, -234.1],\n",
    "                    [5000.5, 150.1],\n",
    "                    [6000.6, -125.1],\n",
    "                    [9000.9, -673.1]])\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# 특성 변환\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# 특성 확인\n",
    "features_standardized"
   ]
  },
  {
   "source": [
    "* 신경망의 모델 파라미터는 작은 난수로 초기화한다.\n",
    "    * 특성값이 모델 파라미터보다 크면 종종 신경망의 성능이 나빠진다.\n",
    "    * 샘플의 특성값이 개별 유닛을 통과하면서 합쳐지므로, 모든 특성은 같은 스케일을 가져야 한다.\n",
    "    * 그래서 각 특성을 모두 평균이 0이고 표준편차 1이되도록 표준화하는 게 가장 좋다.(필수 아니고, 이진 특성인 경우 예외)\n",
    "    "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "평균: 0.0\n표준편차: 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "print(\"평균:\", round(features_standardized[:, 0].mean()))\n",
    "print(\"표준편차:\", features_standardized[:, 0].std())"
   ]
  },
  {
   "source": [
    "## 20.2 신경망 구성하기\n",
    "* 케라스의 Sequential 모델 활용"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# 신경망 모델을 만든다.\n",
    "network = models.Sequential()\n",
    "\n",
    "# 렐루 활성화 함수를 사용한 완전 연결층을 추가한다.\n",
    "network.add(layers.Dense(units=16, activation=\"relu\", input_shape=(10, )))\n",
    "\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# 시그모이드 활성화 함수를 사용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# 신경망의 모델 설정 완료\n",
    "network.compile(loss=\"binary_crossentropy\", # 크로스 엔트로피\n",
    "optimizer=\"rmsprop\", # 옵티마이저\n",
    "metrics=[\"accuracy\"]) # 정확도를 성능 지표로 한다.\n"
   ]
  },
  {
   "source": [
    "* 자주 쓰는 조합 확인\n",
    "    * 이진 분류 : 시그모이드 함수와 하나의 유닛\n",
    "    * 다중 분류 : 소프트맥스 활성화 함수와 k 개의 유닛(k : 타깃 클래스의 개수)\n",
    "    * 회귀 : No 활성화 함수\n",
    "* 손실 함수 정의(예측값이 타깃값과 얼마나 잘 맞는지 측정 함수)\n",
    "    * 이진 분류 : 이진 크로스 엔트로피\n",
    "    * 다중 분류 : 범주형 크로스 엔트로피\n",
    "    * 회귀 : 평균 제곱 오차"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* 옵티 마이저 정의 : 가장 작은 손실 함수 오차를 만드는 모델 파라미터 값 찾기\n",
    "    * 확률적 경사 하강법, 모멘텀(momentum)\n",
    "    * RMSProp(Root Mean Square Propagation), Adam(Adaptive Moment estimation)\n",
    "* 하나 이상의 성능 지표(정확도 등)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* 신경망 제작 방법 두 가지 : 층을 쌓는 방식, 함수형 API(functional API)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_7 (Dense)              (None, 16)                176       \n_________________________________________________________________\ndense_8 (Dense)              (None, 16)                272       \n_________________________________________________________________\ndense_9 (Dense)              (None, 1)                 17        \n=================================================================\nTotal params: 465\nTrainable params: 465\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "source": [
    "* 첫번째 은닉층 : units=16, activation='relu'\n",
    "    * 렐루 활성화 함수를 가진 16개 유닛 구성\n",
    "    * 케라스에서 네트워크의 첫 번째 은닉층 : input_shape 파라미터 포함해야 한다.\n",
    "    * (10,) : 첫 층이 10개의 특성을 가진 샘플을 기대한다.\n",
    "* 두번째 층 : input_shape 매개변수만 없다. 나머지는 동일하다.\n",
    "* 출력층 : 이진 분류가 목적이므로 시그모이드 활성화 함수 사용한 유닛 하나만 포함한다.\n",
    "* 모델 훈련을 위해 케라스에게 네트워크의 훈련 방법 알려준다.\n",
    "    * compile 메서드 :: 최적화 알고리즘(RMSProp), 손실 함수(binary_crossentropy), 하나 이상의 성능 지표를 지정한다.\n",
    "\n",
    "* 케라스 summary 메서드 : 추가된 층 수와 가중치 개수를 보여준다.\n",
    "    * 첫번째 차원은 배치 차원으로, 모델 구성시 None 으로 설정 된다.\n",
    "    * 160개 가중치 + 16개 절편(bias) = 176개와 일치한다.\n",
    "    * 첫 입력층은 입력값 자체이며 훈련되는 가중치가 없다. 그래서 은닉층 2개와 출력층 1개만 확인할 수 있다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력에서 출력까지 3 개의 완전 연결층을 연결한다.\n",
    "x = layers.Input(shape=(10,))\n",
    "h1 = layers.Dense(units=16, activation=\"relu\")(x)\n",
    "h2 = layers.Dense(units=16, activation=\"relu\")(h1)\n",
    "y = layers.Dense(units=1, activation=\"sigmoid\")(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 모델 제작\n",
    "network = models.Model(x, y)\n",
    "\n",
    "# 신경망 모델 설정 완료\n",
    "network.compile(loss=\"binary_crossentropy\",\n",
    "optimizer=\"rmsprop\",\n",
    "metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 10)                0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 16)                176       \n_________________________________________________________________\ndense_11 (Dense)             (None, 16)                272       \n_________________________________________________________________\ndense_12 (Dense)             (None, 1)                 17        \n=================================================================\nTotal params: 465\nTrainable params: 465\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "source": [
    "* Dense 클래스의 객체 생성 부분 + 입력값 주입 부분 나누어 쓰면 더 쉽게 이해할 수 있다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = layers.Dense(units=16, activation=\"relu\")\n",
    "h1 = dense(x)"
   ]
  },
  {
   "source": [
    "* 파이썬 객체 호출시 특수 메서드 __call__ 실행\n",
    "    * Dense 층의 정방향 계산(forward propagation) 수행"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 20.3 이진 분류기 훈련하기\n",
    "* 케라스 사용해서 피드포워드 신경망 만들고 fit 메서드로 훈련"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gurdk\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 0s 18us/step - loss: 0.4195 - accuracy: 0.8120 - val_loss: 0.3394 - val_accuracy: 0.8546\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 0s 14us/step - loss: 0.3225 - accuracy: 0.8641 - val_loss: 0.3284 - val_accuracy: 0.8594\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 0s 14us/step - loss: 0.3107 - accuracy: 0.8691 - val_loss: 0.3392 - val_accuracy: 0.8537\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(0)\n",
    "\n",
    "# 필요한 특성 개수를 지정한다.\n",
    "number_of_features = 1000\n",
    "\n",
    "# 영화 리뷰 데이터에서 훈련 데이터와 타깃 벡터 로드\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "    num_words=number_of_features\n",
    ")\n",
    "\n",
    "# 영화 리뷰 데이터를 원-핫 인코딩된 특성 행렬로 변환\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "\n",
    "# 신경망 모델 제작\n",
    "network = models.Sequential()\n",
    "\n",
    "# 렐루 활성화 함수를 이용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=16, activation=\"relu\", input_shape=(number_of_features,)))\n",
    "\n",
    "# 렐루 활성화 함수를 이용한 완전 연결층\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# 시그모이드 활성화 함수를 사용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# 신경망의 모델 설정 완료\n",
    "network.compile(loss=\"binary_crossentropy\", # 손실 함수 : 이진 크로스엔트로피\n",
    "optimizer=\"rmsprop\", # 옵티마이저\n",
    "metrics=[\"accuracy\"]) # 성능 지표\n",
    "\n",
    "# 신경망 훈련\n",
    "history = network.fit(features_train, # 특성\n",
    "target_train,\n",
    "epochs=3, # 에폭 횟수\n",
    "verbose=1, # 에폭 과정을 출력\n",
    "batch_size = 100, # 배치의 샘플 개수\n",
    "validation_data=(features_test, target_test) # 테스트 데이터\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(25000, 1000)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# 특성 행렬의 크기 확인\n",
    "\n",
    "features_train.shape"
   ]
  },
  {
   "source": [
    "* epochs : 훈련할 때 사용할 에폭 횟수 정의\n",
    "* verbose : 훈련 과정 동안 얼마나 많은 정보 출력할지 결정한다.\n",
    "    * verbose = 0 : 출력 없음\n",
    "    * verbose=1 : 진행 막대 출력\n",
    "    * verbose=2 : 에폭당 한 줄씩 로그 출력\n",
    "* batch_size : 모델 파라미터 업데이트 전에 네트워크 통과시킬 샘플 개수 설정\n",
    "* 모델 평가 위해 사용할 테스트 세트 보관 : validation_data 변수 활용 혹은 validation_split 파라미터로 평가에 사용할 비율 사전 정의 가능하다.\n",
    "* 케라스의 fit : 에폭마다 손실값 + 성능 수치 담긴 History 객체 반환(사이킷런은 훈련 모델을 반환)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 1s 20us/step - loss: 0.3025 - val_loss: 0.3257\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 0s 14us/step - loss: 0.2933 - val_loss: 0.3304\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 0s 14us/step - loss: 0.2819 - val_loss: 0.3268\n"
     ]
    }
   ],
   "source": [
    "# 신경망의 모델 설정 완료\n",
    "network.compile(loss=\"binary_crossentropy\",\n",
    "optimizer = \"rmsprop\")\n",
    "\n",
    "# 신경망 훈련한다.\n",
    "history = network.fit(features_train,\n",
    "target_train,\n",
    "epochs=3,\n",
    "verbose=1,\n",
    "batch_size=100,\n",
    "validation_data = (features_test, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "25000/25000 [==============================] - 0s 10us/step\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.3267870804977417"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "network.evaluate(features_test, target_test)"
   ]
  },
  {
   "source": [
    "* 케라스 내 IMDB 데이터 : 텍스트를 정수의 리스트로 변환한 것이다.\n",
    "    * Tokenizer 클래스 num_words 파라미터 지정 후 sequences_to_matrix 메서드 호출\n",
    "        * num_words보다 큰 정수는 모두 제외하고 mode 파라미터에서 지정한 방식에 맞추어 행렬 제작\n",
    "        * mode = binary : 시퀀스에 등장한 정수에 해당하는 위치에 1 저장\n",
    "        * mode = count : 그 횟수 자체를 저장\n",
    "        * mode = freq : 등장 횟수를 시퀀스의 길이로 나눈다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 20.4 다중 분류기 훈련하기\n",
    "* 케라스 사용해서 출력층에 소프트맥스 활성화 함수를 사용하는 피드포워드 신경망 구성"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 424s 200us/step\n",
      "WARNING:tensorflow:From C:\\Users\\gurdk\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import reuters\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(0)\n",
    "\n",
    "# 필요한 특성 개수를 지정한다.\n",
    "number_of_features = 5000\n",
    "\n",
    "# 특성과 타깃 데이터 로드\n",
    "data= reuters.load_data(num_words=number_of_features)\n",
    "(data_train, target_vector_train), (data_test, target_vector_test) = data\n",
    "\n",
    "# 특성 데이터를 원-핫 인코딩된 특성 행렬로 변환\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "\n",
    "# 타깃 벡터를 원-핫 인코딩하여 타깃 행렬 제작\n",
    "target_train = to_categorical(target_vector_train)\n",
    "target_test = to_categorical(target_vector_test)\n",
    "\n",
    "# 신경망 모델 제작\n",
    "network = models.Sequential()\n",
    "\n",
    "# 렐루 활성화 함수를 사용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=100, activation=\"relu\", input_shape=(number_of_features, )))\n",
    "\n",
    "# 렐루 활성화 함수를 사용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=46, activation=\"softmax\"))\n",
    "\n",
    "# 신경망의 모델 설정을 완료\n",
    "network.compile(loss=\"categorical_crossentropy\",\n",
    "optimizer=\"rmsprop\",\n",
    "metrics=[\"accuracy\"])\n",
    "\n",
    "# 신경망 훈련\n",
    "history = network.fit(features_train,\n",
    "target_train,\n",
    "epochs=3,\n",
    "verbose=0,\n",
    "batch_size=100,\n",
    "validation_data=(features_test, target_test))\n"
   ]
  },
  {
   "source": [
    "* 이진 분류기들과 차이점\n",
    "1. 사용 데이터가 11228개 로이터 뉴스\n",
    "    * 각 뉴스가 46개 토픽으로 분류되어 있고, 이 뉴스를 5000개 이진 특성으로 변환하여 특성 데이터 준비\n",
    "    * 샘플이 속한 46개 클래스를 나타내는 타깃 행렬을 얻고자 원-핫 인코딩하여 타깃 데이터 준비\n",
    "\n",
    "2. 신경망이 46개 클래스 사이에 더 복잡한 관계 표현하도록 은닉층 유닛 수를 늘린다.\n",
    "3. 다중 분류 문제 : 출력층에 소프트맥스 활성화 함수와 46개 유닛(클래스 당 하나씩) 사용\n",
    "    * 소프트맥스 활성화 함수 : 46개 값(총합 1)을 담은 배열을 반환한다.\n",
    "    * 46개 값 : 46개 클래스마다 소속될 확률\n",
    "4. 다중 분류에 맞는 손실 함수인 **범주형 크로스엔트로피** 사용을 위해 CATEGORICAL_CROSSENTROPY 설정"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# 타깃 행렬을 확인한다.\n",
    "target_train"
   ]
  },
  {
   "source": [
    "## 20.5 회귀 모델 훈련하기\n",
    "* 케라스 사용해서 활성화 함수 없이 출력 유닛 하나로 구성된 피드포워드 신경망 제작"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(0)\n",
    "\n",
    "# 특성 행렬과 타깃 벡터 제작\n",
    "features, target = make_regression(n_samples= 10000,\n",
    "n_features=3,\n",
    "n_informative=3,\n",
    "n_targets=1,\n",
    "noise=0.0,\n",
    "random_state=0)\n",
    "\n",
    "# 데이터 훈련 세트와 테스트 세트로 나눈다.\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.33, random_state=0)\n",
    "\n",
    "# 신경망 모델 제작\n",
    "network = models.Sequential()\n",
    "\n",
    "# 렐루 활성화 함수를 사용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=32,\n",
    "                        activation=\"relu\",\n",
    "                        input_shape=(features_train.shape[1],)))\n",
    "\n",
    "# 렐루 활성화 함수를 사용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=32, activation=\"relu\"))\n",
    "\n",
    "# 활성화 함수가 없는 완전 연결층 추가\n",
    "network.add(layers.Dense(units=1))\n",
    "\n",
    "# 렐루 활성화 함수를 사용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=32, activation=\"relu\"))\n",
    "\n",
    "# 활성화 함수가 없는 완전 연결층 추가\n",
    "network.add(layers.Dense(units=1))\n",
    "\n",
    "# 신경망의 모델 설정 완료\n",
    "network.compile(loss=\"mse\", # 평균 제곱 오차\n",
    "                optimizer=\"RMSprop\", # 옵티마이저\n",
    "                metrics=[\"mse\"]) # 성능 지표\n",
    "\n",
    "\n",
    "# 신경망 훈련\n",
    "history = network.fit(\n",
    "    features_train, # 특성\n",
    "    target_train, # 타깃 벡터\n",
    "    epochs=10, # 에폭 횟수\n",
    "    verbose=0, # 출력 없다.\n",
    "    batch_size=100, # 배치의 샘플 개수\n",
    "    validation_data=(features_test, target_test) # 테스트 데이터\n",
    ")"
   ]
  },
  {
   "source": [
    "$$ MSE = {1\\over n} {\\sum_{i=1}^n (\\hat{y}_i - y_i)^2} $$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* 연속적인 값을 예측하는 신경망\n",
    "    * 시그모이드 활성화 함수를 제거하여, 0과 1 사이로 제한하는 것을 없애면 연속적인 값을 출력 가능하다.\n",
    "    * 회귀 모델 훈련하므로, 평균 제곱 오차로 손실 함수 및 평가 지표를 지정한다.\n",
    "* 사이킷런의 make_regression 함수 모의 데이터 사용 : 특성을 표준화할 필요가 없다.\n",
    "    * 그러나 실전에서는 거의 모든 경우 **표준화** 필요."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 20.6 예측하기\n",
    "* 케라스 사용해 피드포워드 신경망 제작 및 predict 메서드로 예측 결과 제작"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gurdk\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# 필요한 특성 개수 지정\n",
    "number_of_features = 10000\n",
    "\n",
    "# IMDB 영화 데이터에서 훈련 데이터와 타깃 벡터 로드\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "    num_words=number_of_features)\n",
    "\n",
    "# IMDB 데이터를 원핫 인코딩된 특성 행렬로 변환\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "\n",
    "# 신경망 모델 제작\n",
    "network = models.Sequential()\n",
    "\n",
    "# 렐루 활성화 함수를 사용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=16,\n",
    "activation='relu',\n",
    "input_shape=(number_of_features, )))\n",
    "\n",
    "# 렐루 활성화 함수 완전 연결층 추가\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# 시그모이드 활성화 함수 완전 연결층 추가\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# 신경망의 모델 설정 완료\n",
    "network.compile(loss=\"binary_crossentropy\",\n",
    "optimizer=\"rmsprop\",\n",
    "metrics=[\"accuracy\"])\n",
    "\n",
    "# 신경망 훈련\n",
    "history = network.fit(features_train, # 특성\n",
    "target_train, # 타깃 벡터\n",
    "epochs=3, # 에폭 횟수\n",
    "verbose=0, # 출력 없음\n",
    "batch_size=100, # 배치의 샘플 개수\n",
    "validation_data=(features_test, target_test)) # 테스트 데이터\n",
    "\n",
    "# 테스트 세트의 클래스 예측\n",
    "predicted_target = network.predict(features_test)"
   ]
  },
  {
   "source": [
    "* 케라스 예측은 쉽다.\n",
    "    * 신경망 훈련 후 특성을 매개변수로 받는 predict 메서드로 각 샘플의 예측값 반환\n",
    "    * network.predict가 핵심이다. 해결에서 이진 분류 신경망을 만들었으니, 예측 결과는 1이 될 확률이다.\n",
    "    * 1에 아주 가까운 값으로 예측된 샘플은 1일 가능성이 매우 높다. 반대도 마찬가지이다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.06130877], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# 첫 번째 샘플이 클래스 1이 될 확률을 확인한다.\n",
    "predicted_target[0]"
   ]
  },
  {
   "source": [
    "## 20.7 훈련 기록 시각화하기\n",
    "* 가장 좋은 신경망의 손실이나 정확도 점수 찾기\n",
    "* matplotlib 라이브러리 사용해 에폭마다 훈련 세트와 테스트 세트의 손실 시각화"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 385.78125 262.19625\" width=\"385.78125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 262.19625 \r\nL 385.78125 262.19625 \r\nL 385.78125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 43.78125 224.64 \r\nL 378.58125 224.64 \r\nL 378.58125 7.2 \r\nL 43.78125 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m9b4258d2bf\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"80.739692\" xlink:href=\"#m9b4258d2bf\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 2 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(77.558442 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"124.220211\" xlink:href=\"#m9b4258d2bf\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 4 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(121.038961 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"167.700731\" xlink:href=\"#m9b4258d2bf\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 6 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(164.519481 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"211.18125\" xlink:href=\"#m9b4258d2bf\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 8 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n      </defs>\r\n      <g transform=\"translate(208 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"254.661769\" xlink:href=\"#m9b4258d2bf\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(248.299269 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"298.142289\" xlink:href=\"#m9b4258d2bf\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 12 -->\r\n      <g transform=\"translate(291.779789 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"341.622808\" xlink:href=\"#m9b4258d2bf\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 14 -->\r\n      <g transform=\"translate(335.260308 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_8\">\r\n     <!-- Epoch -->\r\n     <defs>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 55.90625 72.90625 \r\nL 55.90625 64.59375 \r\nL 19.671875 64.59375 \r\nL 19.671875 43.015625 \r\nL 54.390625 43.015625 \r\nL 54.390625 34.71875 \r\nL 19.671875 34.71875 \r\nL 19.671875 8.296875 \r\nL 56.78125 8.296875 \r\nL 56.78125 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-69\"/>\r\n      <path d=\"M 18.109375 8.203125 \r\nL 18.109375 -20.796875 \r\nL 9.078125 -20.796875 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nz\r\nM 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-112\"/>\r\n      <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n      <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n      <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 75.984375 \r\nL 18.109375 75.984375 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-104\"/>\r\n     </defs>\r\n     <g transform=\"translate(195.870313 252.916562)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\r\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_8\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mbe83118152\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mbe83118152\" y=\"198.977424\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.1 -->\r\n      <defs>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 202.776643)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mbe83118152\" y=\"156.296174\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.2 -->\r\n      <g transform=\"translate(20.878125 160.095393)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mbe83118152\" y=\"113.614924\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.3 -->\r\n      <defs>\r\n       <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 117.414143)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mbe83118152\" y=\"70.933674\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.4 -->\r\n      <g transform=\"translate(20.878125 74.732893)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mbe83118152\" y=\"28.252424\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0.5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 32.051643)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_14\">\r\n     <!-- Loss -->\r\n     <defs>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 8.296875 \r\nL 55.171875 8.296875 \r\nL 55.171875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-76\"/>\r\n      <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n     </defs>\r\n     <g transform=\"translate(14.798438 126.973906)rotate(-90)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-76\"/>\r\n      <use x=\"55.697266\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"116.878906\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"168.978516\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <path clip-path=\"url(#pba1468cf53)\" d=\"M 58.999432 17.083636 \r\nL 80.739692 104.191855 \r\nL 102.479951 135.718596 \r\nL 124.220211 155.727414 \r\nL 145.960471 166.892842 \r\nL 167.700731 173.58292 \r\nL 189.44099 183.690818 \r\nL 211.18125 189.207928 \r\nL 232.92151 194.151939 \r\nL 254.661769 198.50325 \r\nL 276.402029 202.636208 \r\nL 298.142289 208.792309 \r\nL 319.882549 210.76095 \r\nL 341.622808 214.756364 \r\nL 363.363068 214.610014 \r\n\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_14\">\r\n    <path clip-path=\"url(#pba1468cf53)\" d=\"M 58.999432 68.66426 \r\nL 80.739692 104.583744 \r\nL 102.479951 117.687616 \r\nL 124.220211 120.780612 \r\nL 145.960471 86.223918 \r\nL 167.700731 113.103489 \r\nL 189.44099 108.66773 \r\nL 211.18125 103.559465 \r\nL 232.92151 92.540709 \r\nL 254.661769 79.936295 \r\nL 276.402029 85.566569 \r\nL 298.142289 76.794762 \r\nL 319.882549 68.606363 \r\nL 341.622808 58.939737 \r\nL 363.363068 34.470277 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 43.78125 224.64 \r\nL 43.78125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 378.58125 224.64 \r\nL 378.58125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 43.78125 224.64 \r\nL 378.58125 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 43.78125 7.2 \r\nL 378.58125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 50.78125 219.64 \r\nL 146.179688 219.64 \r\nQ 148.179688 219.64 148.179688 217.64 \r\nL 148.179688 189.28375 \r\nQ 148.179688 187.28375 146.179688 187.28375 \r\nL 50.78125 187.28375 \r\nQ 48.78125 187.28375 48.78125 189.28375 \r\nL 48.78125 217.64 \r\nQ 48.78125 219.64 50.78125 219.64 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_15\">\r\n     <path d=\"M 52.78125 195.382187 \r\nL 72.78125 195.382187 \r\n\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_16\"/>\r\n    <g id=\"text_15\">\r\n     <!-- Training loss -->\r\n     <defs>\r\n      <path d=\"M -0.296875 72.90625 \r\nL 61.375 72.90625 \r\nL 61.375 64.59375 \r\nL 35.5 64.59375 \r\nL 35.5 0 \r\nL 25.59375 0 \r\nL 25.59375 64.59375 \r\nL -0.296875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-84\"/>\r\n      <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n      <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n      <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n      <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n      <path d=\"M 45.40625 27.984375 \r\nQ 45.40625 37.75 41.375 43.109375 \r\nQ 37.359375 48.484375 30.078125 48.484375 \r\nQ 22.859375 48.484375 18.828125 43.109375 \r\nQ 14.796875 37.75 14.796875 27.984375 \r\nQ 14.796875 18.265625 18.828125 12.890625 \r\nQ 22.859375 7.515625 30.078125 7.515625 \r\nQ 37.359375 7.515625 41.375 12.890625 \r\nQ 45.40625 18.265625 45.40625 27.984375 \r\nz\r\nM 54.390625 6.78125 \r\nQ 54.390625 -7.171875 48.1875 -13.984375 \r\nQ 42 -20.796875 29.203125 -20.796875 \r\nQ 24.46875 -20.796875 20.265625 -20.09375 \r\nQ 16.0625 -19.390625 12.109375 -17.921875 \r\nL 12.109375 -9.1875 \r\nQ 16.0625 -11.328125 19.921875 -12.34375 \r\nQ 23.78125 -13.375 27.78125 -13.375 \r\nQ 36.625 -13.375 41.015625 -8.765625 \r\nQ 45.40625 -4.15625 45.40625 5.171875 \r\nL 45.40625 9.625 \r\nQ 42.625 4.78125 38.28125 2.390625 \r\nQ 33.9375 0 27.875 0 \r\nQ 17.828125 0 11.671875 7.65625 \r\nQ 5.515625 15.328125 5.515625 27.984375 \r\nQ 5.515625 40.671875 11.671875 48.328125 \r\nQ 17.828125 56 27.875 56 \r\nQ 33.9375 56 38.28125 53.609375 \r\nQ 42.625 51.21875 45.40625 46.390625 \r\nL 45.40625 54.6875 \r\nL 54.390625 54.6875 \r\nz\r\n\" id=\"DejaVuSans-103\"/>\r\n      <path id=\"DejaVuSans-32\"/>\r\n      <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n     </defs>\r\n     <g transform=\"translate(80.78125 198.882187)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"60.865234\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"101.978516\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"163.257812\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"191.041016\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"254.419922\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"282.203125\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"345.582031\" xlink:href=\"#DejaVuSans-103\"/>\r\n      <use x=\"409.058594\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"440.845703\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"468.628906\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"529.810547\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"581.910156\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_17\">\r\n     <path d=\"M 52.78125 210.060312 \r\nL 72.78125 210.060312 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_18\"/>\r\n    <g id=\"text_16\">\r\n     <!-- Test loss -->\r\n     <defs>\r\n      <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n      <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n     </defs>\r\n     <g transform=\"translate(80.78125 213.560312)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"60.818359\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"122.341797\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"174.441406\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"213.650391\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"245.4375\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"273.220703\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"334.402344\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"386.501953\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pba1468cf53\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"43.78125\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 랜덤 시드 설정한다.\n",
    "np.random.seed(0)\n",
    "\n",
    "# 필요한 특성 개수 지정\n",
    "number_of_features = 10000\n",
    "\n",
    "# 영화 리뷰 데이터에서 훈련 데이터와 타깃 벡터 로드하기\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "    num_words=number_of_features)\n",
    "\n",
    "# 영화 리뷰 데이터를 원-핫 인코딩된 특성 행렬로 변환한다.\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "\n",
    "# 신경망 모델 제작\n",
    "network = models.Sequential()\n",
    "\n",
    "# 렐루 활성화 함수를 사용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=16,\n",
    "activation=\"relu\",\n",
    "input_shape=(number_of_features,)))\n",
    "\n",
    "# 렐루 활성화 함수를 사용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# 시그모이드 활성화 함수를 사용한 완전 연결층 추가, 이때는 units=1로 제한된다.\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# 신경망 모델 설정을 종결시킨다. 컴파일 시작.\n",
    "network.compile(loss=\"binary_crossentropy\",\n",
    "optimizer=\"rmsprop\",\n",
    "metrics=[\"accuracy\"])\n",
    "\n",
    "# 신경망 훈련\n",
    "history = network.fit(features_train, # 특성\n",
    "target_train, # 타깃\n",
    "epochs=15, # 에폭 횟수\n",
    "verbose=0, # 출력 제거\n",
    "batch_size=1000, # 배치 당 샘플 개수\n",
    "validation_data=(features_test, target_test)) # 테스트 데이터\n",
    "\n",
    "# 훈련 손실과 테스트 손실의 기록 저장\n",
    "training_loss = history.history[\"loss\"]\n",
    "test_loss = history.history[\"val_loss\"] # 검증 손실은 히스토리 내부에 존재하는 val_loss를 선택한다.and\n",
    "\n",
    "# 에폭 횟수를 사용해서 카운트 객체 만든다.\n",
    "\n",
    "\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# 손실값 기록 시각화\n",
    "plt.plot(epoch_count, training_loss, \"r--\")\n",
    "plt.plot(epoch_count, test_loss, \"b-\")\n",
    "plt.legend([\"Training loss\", \"Test loss\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 392.14375 262.19625\" width=\"392.14375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 262.19625 \r\nL 392.14375 262.19625 \r\nL 392.14375 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 50.14375 224.64 \r\nL 384.94375 224.64 \r\nL 384.94375 7.2 \r\nL 50.14375 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mb44a73cc6d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"87.102192\" xlink:href=\"#mb44a73cc6d\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 2 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(83.920942 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"130.582711\" xlink:href=\"#mb44a73cc6d\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 4 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(127.401461 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"174.063231\" xlink:href=\"#mb44a73cc6d\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 6 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(170.881981 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"217.54375\" xlink:href=\"#mb44a73cc6d\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 8 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n      </defs>\r\n      <g transform=\"translate(214.3625 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"261.024269\" xlink:href=\"#mb44a73cc6d\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(254.661769 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"304.504789\" xlink:href=\"#mb44a73cc6d\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 12 -->\r\n      <g transform=\"translate(298.142289 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"347.985308\" xlink:href=\"#mb44a73cc6d\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 14 -->\r\n      <g transform=\"translate(341.622808 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_8\">\r\n     <!-- Epoch -->\r\n     <defs>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 55.90625 72.90625 \r\nL 55.90625 64.59375 \r\nL 19.671875 64.59375 \r\nL 19.671875 43.015625 \r\nL 54.390625 43.015625 \r\nL 54.390625 34.71875 \r\nL 19.671875 34.71875 \r\nL 19.671875 8.296875 \r\nL 56.78125 8.296875 \r\nL 56.78125 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-69\"/>\r\n      <path d=\"M 18.109375 8.203125 \r\nL 18.109375 -20.796875 \r\nL 9.078125 -20.796875 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nz\r\nM 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-112\"/>\r\n      <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n      <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n      <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 75.984375 \r\nL 18.109375 75.984375 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-104\"/>\r\n     </defs>\r\n     <g transform=\"translate(202.232813 252.916562)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\r\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_8\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m326e48a219\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m326e48a219\" y=\"181.732818\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.80 -->\r\n      <defs>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 185.532036)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m326e48a219\" y=\"136.667906\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.85 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 140.467125)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m326e48a219\" y=\"91.602995\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.90 -->\r\n      <defs>\r\n       <path d=\"M 10.984375 1.515625 \r\nL 10.984375 10.5 \r\nQ 14.703125 8.734375 18.5 7.8125 \r\nQ 22.3125 6.890625 25.984375 6.890625 \r\nQ 35.75 6.890625 40.890625 13.453125 \r\nQ 46.046875 20.015625 46.78125 33.40625 \r\nQ 43.953125 29.203125 39.59375 26.953125 \r\nQ 35.25 24.703125 29.984375 24.703125 \r\nQ 19.046875 24.703125 12.671875 31.3125 \r\nQ 6.296875 37.9375 6.296875 49.421875 \r\nQ 6.296875 60.640625 12.9375 67.421875 \r\nQ 19.578125 74.21875 30.609375 74.21875 \r\nQ 43.265625 74.21875 49.921875 64.515625 \r\nQ 56.59375 54.828125 56.59375 36.375 \r\nQ 56.59375 19.140625 48.40625 8.859375 \r\nQ 40.234375 -1.421875 26.421875 -1.421875 \r\nQ 22.703125 -1.421875 18.890625 -0.6875 \r\nQ 15.09375 0.046875 10.984375 1.515625 \r\nz\r\nM 30.609375 32.421875 \r\nQ 37.25 32.421875 41.125 36.953125 \r\nQ 45.015625 41.5 45.015625 49.421875 \r\nQ 45.015625 57.28125 41.125 61.84375 \r\nQ 37.25 66.40625 30.609375 66.40625 \r\nQ 23.96875 66.40625 20.09375 61.84375 \r\nQ 16.21875 57.28125 16.21875 49.421875 \r\nQ 16.21875 41.5 20.09375 36.953125 \r\nQ 23.96875 32.421875 30.609375 32.421875 \r\nz\r\n\" id=\"DejaVuSans-57\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 95.402213)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m326e48a219\" y=\"46.538083\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.95 -->\r\n      <g transform=\"translate(20.878125 50.337302)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_13\">\r\n     <!-- Accuracy Score -->\r\n     <defs>\r\n      <path d=\"M 34.1875 63.1875 \r\nL 20.796875 26.90625 \r\nL 47.609375 26.90625 \r\nz\r\nM 28.609375 72.90625 \r\nL 39.796875 72.90625 \r\nL 67.578125 0 \r\nL 57.328125 0 \r\nL 50.6875 18.703125 \r\nL 17.828125 18.703125 \r\nL 11.1875 0 \r\nL 0.78125 0 \r\nz\r\n\" id=\"DejaVuSans-65\"/>\r\n      <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\n\" id=\"DejaVuSans-117\"/>\r\n      <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n      <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n      <path d=\"M 32.171875 -5.078125 \r\nQ 28.375 -14.84375 24.75 -17.8125 \r\nQ 21.140625 -20.796875 15.09375 -20.796875 \r\nL 7.90625 -20.796875 \r\nL 7.90625 -13.28125 \r\nL 13.1875 -13.28125 \r\nQ 16.890625 -13.28125 18.9375 -11.515625 \r\nQ 21 -9.765625 23.484375 -3.21875 \r\nL 25.09375 0.875 \r\nL 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 11.921875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-121\"/>\r\n      <path id=\"DejaVuSans-32\"/>\r\n      <path d=\"M 53.515625 70.515625 \r\nL 53.515625 60.890625 \r\nQ 47.90625 63.578125 42.921875 64.890625 \r\nQ 37.9375 66.21875 33.296875 66.21875 \r\nQ 25.25 66.21875 20.875 63.09375 \r\nQ 16.5 59.96875 16.5 54.203125 \r\nQ 16.5 49.359375 19.40625 46.890625 \r\nQ 22.3125 44.4375 30.421875 42.921875 \r\nL 36.375 41.703125 \r\nQ 47.40625 39.59375 52.65625 34.296875 \r\nQ 57.90625 29 57.90625 20.125 \r\nQ 57.90625 9.515625 50.796875 4.046875 \r\nQ 43.703125 -1.421875 29.984375 -1.421875 \r\nQ 24.8125 -1.421875 18.96875 -0.25 \r\nQ 13.140625 0.921875 6.890625 3.21875 \r\nL 6.890625 13.375 \r\nQ 12.890625 10.015625 18.65625 8.296875 \r\nQ 24.421875 6.59375 29.984375 6.59375 \r\nQ 38.421875 6.59375 43.015625 9.90625 \r\nQ 47.609375 13.234375 47.609375 19.390625 \r\nQ 47.609375 24.75 44.3125 27.78125 \r\nQ 41.015625 30.8125 33.5 32.328125 \r\nL 27.484375 33.5 \r\nQ 16.453125 35.6875 11.515625 40.375 \r\nQ 6.59375 45.0625 6.59375 53.421875 \r\nQ 6.59375 63.09375 13.40625 68.65625 \r\nQ 20.21875 74.21875 32.171875 74.21875 \r\nQ 37.3125 74.21875 42.625 73.28125 \r\nQ 47.953125 72.359375 53.515625 70.515625 \r\nz\r\n\" id=\"DejaVuSans-83\"/>\r\n      <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n     </defs>\r\n     <g transform=\"translate(14.798438 154.537187)rotate(-90)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-65\"/>\r\n      <use x=\"68.392578\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"123.373047\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"178.353516\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"241.732422\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"282.845703\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"344.125\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"399.105469\" xlink:href=\"#DejaVuSans-121\"/>\r\n      <use x=\"458.285156\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"490.072266\" xlink:href=\"#DejaVuSans-83\"/>\r\n      <use x=\"553.548828\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"608.529297\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"669.710938\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"710.792969\" xlink:href=\"#DejaVuSans-101\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_12\">\r\n    <path clip-path=\"url(#p9065d1ec65)\" d=\"M 65.361932 214.756364 \r\nL 87.102192 95.821072 \r\nL 108.842451 75.812262 \r\nL 130.582711 64.419853 \r\nL 152.322971 56.344213 \r\nL 174.063231 50.575914 \r\nL 195.80349 40.733748 \r\nL 217.54375 37.561167 \r\nL 239.28401 34.244398 \r\nL 261.024269 31.46839 \r\nL 282.764529 26.637425 \r\nL 304.504789 22.166985 \r\nL 326.245049 20.256217 \r\nL 347.985308 17.083636 \r\nL 369.725568 18.705974 \r\n\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <path clip-path=\"url(#p9065d1ec65)\" d=\"M 65.361932 123.472902 \r\nL 87.102192 107.249528 \r\nL 108.842451 102.130132 \r\nL 130.582711 102.274374 \r\nL 152.322971 131.656684 \r\nL 174.063231 109.448674 \r\nL 195.80349 111.503685 \r\nL 217.54375 112.54916 \r\nL 239.28401 117.560361 \r\nL 261.024269 122.46342 \r\nL 282.764529 117.416172 \r\nL 304.504789 119.867702 \r\nL 326.245049 121.742423 \r\nL 347.985308 122.64371 \r\nL 369.725568 132.73826 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 50.14375 224.64 \r\nL 50.14375 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 384.94375 224.64 \r\nL 384.94375 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 50.14375 224.64 \r\nL 384.94375 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 50.14375 7.2 \r\nL 384.94375 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 57.14375 44.55625 \r\nL 176.278125 44.55625 \r\nQ 178.278125 44.55625 178.278125 42.55625 \r\nL 178.278125 14.2 \r\nQ 178.278125 12.2 176.278125 12.2 \r\nL 57.14375 12.2 \r\nQ 55.14375 12.2 55.14375 14.2 \r\nL 55.14375 42.55625 \r\nQ 55.14375 44.55625 57.14375 44.55625 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_14\">\r\n     <path d=\"M 59.14375 20.298437 \r\nL 79.14375 20.298437 \r\n\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_15\"/>\r\n    <g id=\"text_14\">\r\n     <!-- Traning Accuracy -->\r\n     <defs>\r\n      <path d=\"M -0.296875 72.90625 \r\nL 61.375 72.90625 \r\nL 61.375 64.59375 \r\nL 35.5 64.59375 \r\nL 35.5 0 \r\nL 25.59375 0 \r\nL 25.59375 64.59375 \r\nL -0.296875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-84\"/>\r\n      <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n      <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n      <path d=\"M 45.40625 27.984375 \r\nQ 45.40625 37.75 41.375 43.109375 \r\nQ 37.359375 48.484375 30.078125 48.484375 \r\nQ 22.859375 48.484375 18.828125 43.109375 \r\nQ 14.796875 37.75 14.796875 27.984375 \r\nQ 14.796875 18.265625 18.828125 12.890625 \r\nQ 22.859375 7.515625 30.078125 7.515625 \r\nQ 37.359375 7.515625 41.375 12.890625 \r\nQ 45.40625 18.265625 45.40625 27.984375 \r\nz\r\nM 54.390625 6.78125 \r\nQ 54.390625 -7.171875 48.1875 -13.984375 \r\nQ 42 -20.796875 29.203125 -20.796875 \r\nQ 24.46875 -20.796875 20.265625 -20.09375 \r\nQ 16.0625 -19.390625 12.109375 -17.921875 \r\nL 12.109375 -9.1875 \r\nQ 16.0625 -11.328125 19.921875 -12.34375 \r\nQ 23.78125 -13.375 27.78125 -13.375 \r\nQ 36.625 -13.375 41.015625 -8.765625 \r\nQ 45.40625 -4.15625 45.40625 5.171875 \r\nL 45.40625 9.625 \r\nQ 42.625 4.78125 38.28125 2.390625 \r\nQ 33.9375 0 27.875 0 \r\nQ 17.828125 0 11.671875 7.65625 \r\nQ 5.515625 15.328125 5.515625 27.984375 \r\nQ 5.515625 40.671875 11.671875 48.328125 \r\nQ 17.828125 56 27.875 56 \r\nQ 33.9375 56 38.28125 53.609375 \r\nQ 42.625 51.21875 45.40625 46.390625 \r\nL 45.40625 54.6875 \r\nL 54.390625 54.6875 \r\nz\r\n\" id=\"DejaVuSans-103\"/>\r\n     </defs>\r\n     <g transform=\"translate(87.14375 23.798437)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"60.865234\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"101.978516\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"163.257812\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"226.636719\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"254.419922\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"317.798828\" xlink:href=\"#DejaVuSans-103\"/>\r\n      <use x=\"381.275391\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"413.0625\" xlink:href=\"#DejaVuSans-65\"/>\r\n      <use x=\"481.455078\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"536.435547\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"591.416016\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"654.794922\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"695.908203\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"757.1875\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"812.167969\" xlink:href=\"#DejaVuSans-121\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_16\">\r\n     <path d=\"M 59.14375 34.976562 \r\nL 79.14375 34.976562 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_17\"/>\r\n    <g id=\"text_15\">\r\n     <!-- Test Accuracy -->\r\n     <defs>\r\n      <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n      <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n     </defs>\r\n     <g transform=\"translate(87.14375 38.476562)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"60.818359\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"122.341797\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"174.441406\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"213.650391\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"245.4375\" xlink:href=\"#DejaVuSans-65\"/>\r\n      <use x=\"313.830078\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"368.810547\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"423.791016\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"487.169922\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"528.283203\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"589.5625\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"644.542969\" xlink:href=\"#DejaVuSans-121\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p9065d1ec65\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"50.14375\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# 같은 방식으로 에폭마다 훈련 정확도와 테스트 정확도 그래프 그리기\n",
    "\n",
    "# 훈련 정확도 및 검증 정확도 기록 저장\n",
    "training_accuracy = history.history[\"accuracy\"]\n",
    "test_accuracy = history.history[\"val_accuracy\"]\n",
    "plt.plot(epoch_count, training_accuracy, \"r--\")\n",
    "plt.plot(epoch_count, test_accuracy, \"b-\")\n",
    "\n",
    "# 정확도 그래프 그리기\n",
    "plt.legend([\"Traning Accuracy\", \"Test Accuracy\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.show();\n",
    "\n"
   ]
  },
  {
   "source": [
    "* 신경망 : 성능이 초반에 안 좋다. \n",
    "* 훈련 데이터를 학습함에 따라 테스트 세트에 대한 모델의 오차가 감소하는 경향을 보인다.\n",
    "* 특정 지점 부터 과적합하게 되며, 훈련 오차가 감소하나 테스트 오차가 증가하기 시작한다.\n",
    "    * 테스트 오차가 가장 낮은 지점이 최적점이 된다.\n",
    "    * 해결에 있는 에폭 대비 훈련 손실과 테스트 손실 그래프에서 잘 볼 수 있다.\n",
    "        * 여기서는 4 ~ 5 에폭에서 가장 낮고 그 이후부터 훈련 손실이 감소하나 테스트 손실이 증가함을 확인할 수 있다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 20.8 가중치 규제로 과대적합 줄이기\n",
    "* 과대적합 줄이자.\n",
    "* 가중치 규제(weight regularization) : 네트워크의 모델 파라미터에 제한을 준다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(0)\n",
    "\n",
    "# 필요한 특성 개수 지정\n",
    "number_of_features = 1000\n",
    "\n",
    "# 영화 리뷰 데이터에서 훈련 데이터와 타깃 벡터를 로드한다.\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(num_words=number_of_features)\n",
    "\n",
    "# 영화 리뷰 데이터를 ㅜ언핫 인코딩된 특성 행렬로 변환\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "\n",
    "# 신경망 모델 제작\n",
    "network = models.Sequential()\n",
    "\n",
    "# 렐루 활성화 함수를 사용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=16,\n",
    "activation=\"relu\",\n",
    "input_shape=(number_of_features,)))\n",
    "\n",
    "# 렐루 활성화 함수를 사용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# 시그모이드 활성화 함수를 사용한 완전 연결층 추가(출력층)\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# 신경망 모델 설정 컴파일\n",
    "network.compile(\n",
    "    loss=\"binary_crossentropy\",#손실 함수\n",
    "    optimizer=\"rmsprop\",# 옵티마이저\n",
    "    metrics=[\"accuracy\"] # 성능 지표\n",
    "    )\n",
    "\n",
    "# 신경망 훈련\n",
    "history = network.fit(features_train,# 특성\n",
    "                        target_train, # 타깃 벡터\n",
    "                        epochs=20, # 에폭 횟수\n",
    "                        verbose=0, # 출력 없음\n",
    "                        batch_size=100, # 배치의 샘플 개수\n",
    "                        validation_data=(features_test, target_test)) # 테스트 데이터"
   ]
  },
  {
   "source": [
    "* callbacks가 사라진 것으로 보인다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* 신경망의 과적합 전략\n",
    "    * 신경망의 모델 파라미터(가중치)가 작은 값을 갖도록 제한을 가한다.\n",
    "    * 더 간단한 모델을 만들기 때문에 과적합 가능성이 적다.\n",
    "        * **가중치 규제** 혹은 **가중치 감소(weights decay)**라고 부른다.\n",
    "    * 가중치 규제로 L2 노름 같은 패널티를 손실 함수에 추가한다.\n",
    "* 케라스 층의 매개변수 : kernel_regularizer=regularizers.l2(0.01) 지정\n",
    "    * 가중치 규제를 추가할 수 있다.\n",
    "    * 0.01 : 큰 쪽의 모델 파라미터 값에 얼마나 패널티를 부여할지를 결정한다. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* keras_regularizers 모듈 : l1, l2, l1_l2 함수로 지정할 수 있다.\n",
    "    * l1, l2, l1_l2(l1=0.01, l2=0.01) 이렇게 규제를 조절할 수 있다.\n",
    "    * l1_l2 : 엘라스틱 넷 패널티 부여 가능\n",
    "    * 함수 기본값의 경우 명시적으로 전달하지 않고 문자열로 지정할 수도 있다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.add(layers.Dense(units=16,\n",
    "activation=\"relu\",\n",
    "kernel_regularizer=\"l1_l2\",\n",
    "input_shape=(number_of_features,)))"
   ]
  },
  {
   "source": [
    "## 20.9 조기종료로 과대적합 줄이기\n",
    "* 테스트 손실이 더 이상 감소하지 않을 때 훈련을 멈춘다.(조기 종료, early stopping)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(0)\n",
    "\n",
    "# 필요한 특성 개수 지정\n",
    "number_of_features = 1000\n",
    "\n",
    "# 영화 리뷰 데이터에서 훈련 데이터와 타깃 벡터를 로드한다.\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "    num_words=number_of_features)\n",
    "\n",
    "# 영화 리뷰 데이터를 원핫 인코딩된 특성 행렬로 변환한다.\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "\n",
    "# 신경망 모델 제작\n",
    "network = models.Sequential()\n",
    "\n",
    "# 렐루 활성화 함수를 사용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=16,\n",
    "activation=\"relu\",\n",
    "input_shape=(number_of_features,)))\n",
    "\n",
    "# 렐루 활성화 함수를 사용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# 시그모이드 활성화 함수를 사용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# 신경망의 모델 설정을 완료합니다.\n",
    "network.compile(loss=\"binary_crossentropy\",\n",
    "optimizer=\"rmsprop\",\n",
    "metrics=[\"accuracy\"])\n",
    "\n",
    "# 훈련을 조기종료하고 최선의 모델을 저장하기 위해 콜백 함수를 설정한다.\n",
    "callbacks = [EarlyStopping(monitor=\"val_loss\", patience=2),\n",
    "ModelCheckpoint(filepath=\"best_model.h5\",\n",
    "                monitor=\"val_loss\",\n",
    "                save_best_only=True)]\n",
    "\n",
    "# 신경망 훈련\n",
    "history = network.fit(features_train,\n",
    "target_train,\n",
    "epochs=20,\n",
    "callbacks=callbacks,\n",
    "verbose=0,\n",
    "batch_size=100,\n",
    "validation_data=(features_test, target_test))"
   ]
  },
  {
   "source": [
    "* 훈련 초기에는 훈련 오차와 테스트 오차가 감소한다.\n",
    "    * 특정 지점에서 네트워크가 훈련 데이터를 **기억**하기 시작한다.\n",
    "    * 훈련 오차가 그래서 계속 감소하나 테스트 오차는 증가하기 시작한다.\n",
    "    * 과대적합 발생한다.\n",
    "    * 조기 종료 : 훈련 과정을 감시하여 테스트 오차가 증가하기 시작할 때 훈련 중지한다.(콜백 함수 in 케라스)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* ModelCheckpoint : 에폭마다 모델을 파일에 저장\n",
    "    * save_best_only=True로 지정하면, 최선의 모델만 저장한다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 20.10 드롭아웃으로 과대적합 줄이기\n",
    "* 드롭아웃(dropout) : 네트워크에 구조적으로 잡음 추가"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import numpy as numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(0)\n",
    "\n",
    "# 필요한 특성 개수 지정\n",
    "number_of_features = 1000\n",
    "\n",
    "# 영화 리뷰 데이터에서 훈련 데이터와 타깃 벡터 로드\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "    num_words=number_of_features)\n",
    "\n",
    "# 영화 리뷰 데이터를 원핫 인코딩된 특성 행렬로 변환\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_Test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "\n",
    "# 신경망 모델 제작\n",
    "network = models.Sequential()\n",
    "\n",
    "# 입력층으로 드롭아웃 추가\n",
    "network.add(layers.Dropout(0.2, input_shape=(number_of_features, )))\n",
    "\n",
    "# 렐루 활성화 함수를 사용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# 드롭 아웃 층을 추가\n",
    "network.add(layers.Dropout(0.5))\n",
    "\n",
    "# 다시 렐루 활성화 함수 사용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# 드롭 아웃 층을 추가\n",
    "network.add(layers.Dropout(0.5))\n",
    "\n",
    "# 시그모이드 활성화 함수 사용한 완전 연결층(출력층) 추가\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# 신경망 모델 설정 컴파일\n",
    "network.compile(loss=\"binary_crossentropy\",\n",
    "optimizer=\"rmsprop\",\n",
    "metrics=[\"accuracy\"])\n",
    "\n",
    "# 신경망 훈련\n",
    "history = network.fit(features_train,\n",
    "target_train,\n",
    "epochs=3,\n",
    "verbose=0,\n",
    "batch_size=100,\n",
    "validation_data=(features_test, target_test))\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 54,
   "outputs": []
  },
  {
   "source": [
    "* 드롭아웃 : 신경망 규제하는 강력하고 인기 높은 방법.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 20.11 모델 훈련 진행 과정을 저장하기\n",
    "* 콜백 함수 ModelCheckpoint 사용해서 에폭이 끝날 때마다 모델 저장"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(0)\n",
    "\n",
    "# 필요한 특성 개수 지정\n",
    "number_of_features = 1000\n",
    "\n",
    "# 영화 리뷰 데이터에서 훈련 데이터와 타깃 벡터 로드\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "    num_words=number_of_features)\n",
    "\n",
    "# 영화 리뷰 데이터를 원핫 인코딩된 특성 행렬로 변환\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "\n",
    "# 신경망 모델을 만든다.\n",
    "network = models.Sequential()\n",
    "\n",
    "# 렐루 활성화 함수를 사용한 완전 연결층을 추가한다.\n",
    "network.add(layers.Dense(units=16, activation=\"relu\", input_shape=(number_of_features,)))\n",
    "\n",
    "# 다시 렐루 추가\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# 시그모이드 활성화 함수 사용한 완전 연결층 추가(출력)\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# 신경망 모델 설정\n",
    "network.compile(loss=\"binary_crossentropy\", # 크로스 엔트로피\n",
    "optimizer = \"rmsprop\", # 옵티마이저\n",
    "metrics=[\"accuracy\"]) # 성능 지표\n",
    "\n",
    "# 훈련 조기 종료 및 최선의 모델 저장을 위해 콜백 함수 설정\n",
    "checkpoint = [ModelCheckpoint(filepath=\"models.hdf5\")]\n",
    "\n",
    "# 신경망 훈련\n",
    "history = network.fit(features_train,\n",
    "target_train,\n",
    "epochs=5,\n",
    "callbacks=checkpoint,\n",
    "verbose=0,\n",
    "batch_size=100,\n",
    "validation_data=(features_test, target_test)) # 테스트 데이터"
   ]
  },
  {
   "source": [
    "* 조기 중단\n",
    "    * ModelCheckpoint, EarlyStopping 함께 사용하여 테스트 오차가 더 증가되지 않을 때를 관찰하고 훈련을 중지했다.\n",
    "    * ModelCheckpoint : 에폭이 끝날 때마다 모델을 저장한다.\n",
    "        * 에폭 마칠 때마다 filepath 파라미터에 지정된 위치에 모델을 저장한다.\n",
    "        * 파일 이름만 지정했다면 에폭마다 최신 모델로 덮어 쓸 것이다.\n",
    "        * 손실 함수의 성능에 따라 최상의 모델만 저장하고 싶다면, save_best_only = True 그리고 monitor='val_loss' 설정한다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 20.12 신경망을 k-폴드 교차검증하기\n",
    "* k-폴드 교차검증을 사용해서 신경망 평가\n",
    "    * 필수적이나 권장되지 않는다.\n",
    "    * 사이킷런 래퍼(wrapper)로 케라스 내 Sequential 모델에서 사이킷런 API 사용 가능하다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# 랜덤 시드\n",
    "np.random.seed(0)\n",
    "\n",
    "# 특성 개수\n",
    "number_of_features = 100\n",
    "\n",
    "# 특성 행렬과 타깃 벡터를 만든다.\n",
    "features, target = make_classification(n_samples=10000,\n",
    "n_features= number_of_features,\n",
    "n_informative= 3,\n",
    "n_redundant= 0,\n",
    "n_classes=2,\n",
    "weights=[.5, .5],\n",
    "random_state=0)\n",
    "\n"
   ]
  },
  {
   "source": [
    "# 설정 완료된 신경망을 반환하는 함수를 만든다.\n",
    "def create_network():\n",
    "\n",
    "    # 신경망 모델을 만든다.\n",
    "    network = models.Sequential()\n",
    "\n",
    "    # 렐루 활성화 함수를 사용한 완전 연결층을 추가한다.\n",
    "    network.add(layers.Dense(units=16, activation=\"relu\", input_shape=(number_of_features,)))\n",
    "\n",
    "    # 렐루 활성화 함수를 사용한 완전 연결층 추가\n",
    "    network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "    # 시그모이드 FC 추가\n",
    "    network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # 신경망 모델 설정 완료\n",
    "    network.compile(loss=\"binary_crossentropy\",\n",
    "    optimizer=\"rmsprop\",\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "    return network\n",
    "\n",
    "# 케라스 모델 래핑하여 사이킷런에서 사용하도록 만든다.\n",
    "neural_network = KerasClassifier(build_fn=create_network,\n",
    "                                epochs=10,\n",
    "                                batch_size=100,\n",
    "                                verbose=0)\n",
    "\n",
    "# 3-폴드 교차검증을 사용하여 신경망을 평가합니다.\n",
    "cross_val_score(neural_network, features, target, cv=3)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 61,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.90491903, 0.77737772, 0.86858684])"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ]
  },
  {
   "source": [
    "* 신경망은 시간이 오래 걸리므로 k폴드 교차검증은 권장하지 않는다.\n",
    "    * 데이터가 적은 경우에는 해볼 수 있다.\n",
    "    * 케라스 신경망 모델을 사이킷런으로 래퍼하면, 서로 호환이 되어 k-fold cv 외에 다양한 평가 도구 사용 가능하다.\n",
    "        * compile 메서드까지 완료한 신경망을 반환하는 함수를 제작한다.\n",
    "        * KerasClassifier(KerasRegressor) : 이후부터 이 모델을 다른 사이킷런 학습 알고리즘처럼 사용 가능하다.\n",
    "            * cross_val_score 함수에 신경망 모델을 넣고, 3-폴드 교차검증을 수행했다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 20.13 신경망 튜닝하기\n",
    "* 케라스 모델과 GridSearchCV와 같은 사이킷런의 모델 선택 도구를 연결한다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(0)\n",
    "\n",
    "# 특성 개수\n",
    "number_of_features = 100\n",
    "\n",
    "# 특성 행렬과 타깃 벡터를 제작한다.\n",
    "features, target = make_classification(n_samples=10000,\n",
    "n_features = number_of_features,\n",
    "n_informative=3,\n",
    "n_redundant=0,\n",
    "n_classes=2,\n",
    "weights=[.5, .5],\n",
    "random_state=0)\n",
    "\n",
    "# 설정 완료된 신경망을 반환하는 함수 제작\n",
    "def create_network(optimizer=\"rmsprop\"):\n",
    "\n",
    "    # 신경망 모델을 만든다.\n",
    "    network = models.Sequential()\n",
    "\n",
    "    # 렐루 활성화 함수를 사용한 완전 연결층 추가\n",
    "    network.add(layers.Dense(units=16,\n",
    "    activation=\"relu\",\n",
    "    input_shape=(number_of_features,)))\n",
    "\n",
    "    # 렐루 활성화 함수를 사용한 완전 연결층을 추가\n",
    "    network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "    # 시그모이드 활성화 함수를 사용한 완전 연결층 추가\n",
    "    network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # 신경망의 모델 설정을 완료\n",
    "    network.compile(loss=\"binary_crossentropy\",\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런에서 사용하도록 케라스 모델을 감싼다.\n",
    "neural_network = KerasClassifier(build_fn=create_network, verbose=0)\n",
    "\n",
    "# 하이퍼파라미터 탐색영역을 정의한다.\n",
    "epochs= [5, 10]\n",
    "batches = [5, 10, 100]\n",
    "optimizers = [\"rmsprop\", \"adam\"]\n",
    "\n",
    "# 하이퍼파라미터 그리드를 만든다.\n",
    "hyperparameters = dict(optimizer=optimizers, epochs=epochs, batch_size=batches)\n",
    "\n",
    "# 그리드 서치 제작\n",
    "grid = GridSearchCV(estimator=neural_network, param_grid=hyperparameters)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_result = grid.fit(features, target)"
   ]
  },
  {
   "source": [
    "* 사이킷런 모델에서 최상의 하이퍼파라미터를 찾기 위한 모델 선택 도구를 다루었다.\n",
    "    * 신경망의 자동 하이퍼파라미터 튜닝이 답은 아니지만 유용할 수 있다.\n",
    "    * 그리드 서치 모델 선택 전략이 좋다고 생각하기 전에 굉장히 시간이 오래 걸린다.\n",
    "    * 해결에서 최적화 알고리즘, 에폭 횟수, 배치 크기 등 여러 옵션을 대상으로 교차 검증 그리드 서치를 수행했다.\n",
    "    * 예제 실행에 몇 분 걸리나 완료되면, best_params_ 속성에서 최상의 결과 내는 신경망 하이퍼파라미터를 볼 수 있다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'batch_size': 10, 'epochs': 5, 'optimizer': 'adam'}"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "# 최상의 신경망 하이퍼파라미터 확인\n",
    "grid_result.best_params_"
   ]
  },
  {
   "source": [
    "## 20.14 신경망 시각화하기\n",
    "* 신경망 구조 시각화는, 케라스의 model_to_dot, plot_model 사용"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ],
      "image/svg+xml": "<svg height=\"405pt\" viewBox=\"0.00 0.00 307.00 304.00\" width=\"409pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.33333 1.33333) rotate(0) translate(4 300)\">\n<title>G</title>\n<polygon fill=\"white\" points=\"-4,4 -4,-300 303,-300 303,4 -4,4\" stroke=\"none\"/>\n<!-- 1704565767688 -->\n<g class=\"node\" id=\"node1\"><title>1704565767688</title>\n<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 299,-295.5 299,-249.5 0,-249.5\" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-268.8\">dense_1_input: InputLayer</text>\n<polyline fill=\"none\" points=\"166,-249.5 166,-295.5 \" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"166,-272.5 222,-272.5 \" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"222,-249.5 222,-295.5 \" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"260.5\" y=\"-280.3\">(None, 10)</text>\n<polyline fill=\"none\" points=\"222,-272.5 299,-272.5 \" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"260.5\" y=\"-257.3\">(None, 10)</text>\n</g>\n<!-- 1704408669640 -->\n<g class=\"node\" id=\"node2\"><title>1704408669640</title>\n<polygon fill=\"none\" points=\"31,-166.5 31,-212.5 268,-212.5 268,-166.5 31,-166.5\" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-185.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"135,-166.5 135,-212.5 \" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"135,-189.5 191,-189.5 \" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"191,-166.5 191,-212.5 \" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229.5\" y=\"-197.3\">(None, 10)</text>\n<polyline fill=\"none\" points=\"191,-189.5 268,-189.5 \" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229.5\" y=\"-174.3\">(None, 16)</text>\n</g>\n<!-- 1704565767688&#45;&gt;1704408669640 -->\n<g class=\"edge\" id=\"edge1\"><title>1704565767688-&gt;1704408669640</title>\n<path d=\"M149.5,-249.366C149.5,-241.152 149.5,-231.658 149.5,-222.725\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"153,-222.607 149.5,-212.607 146,-222.607 153,-222.607\" stroke=\"black\"/>\n</g>\n<!-- 1704565765000 -->\n<g class=\"node\" id=\"node3\"><title>1704565765000</title>\n<polygon fill=\"none\" points=\"31,-83.5 31,-129.5 268,-129.5 268,-83.5 31,-83.5\" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-102.8\">dense_2: Dense</text>\n<polyline fill=\"none\" points=\"135,-83.5 135,-129.5 \" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"135,-106.5 191,-106.5 \" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"191,-83.5 191,-129.5 \" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229.5\" y=\"-114.3\">(None, 16)</text>\n<polyline fill=\"none\" points=\"191,-106.5 268,-106.5 \" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229.5\" y=\"-91.3\">(None, 16)</text>\n</g>\n<!-- 1704408669640&#45;&gt;1704565765000 -->\n<g class=\"edge\" id=\"edge2\"><title>1704408669640-&gt;1704565765000</title>\n<path d=\"M149.5,-166.366C149.5,-158.152 149.5,-148.658 149.5,-139.725\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"153,-139.607 149.5,-129.607 146,-139.607 153,-139.607\" stroke=\"black\"/>\n</g>\n<!-- 1704566174856 -->\n<g class=\"node\" id=\"node4\"><title>1704566174856</title>\n<polygon fill=\"none\" points=\"31,-0.5 31,-46.5 268,-46.5 268,-0.5 31,-0.5\" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-19.8\">dense_3: Dense</text>\n<polyline fill=\"none\" points=\"135,-0.5 135,-46.5 \" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"135,-23.5 191,-23.5 \" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"191,-0.5 191,-46.5 \" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229.5\" y=\"-31.3\">(None, 16)</text>\n<polyline fill=\"none\" points=\"191,-23.5 268,-23.5 \" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229.5\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 1704565765000&#45;&gt;1704566174856 -->\n<g class=\"edge\" id=\"edge3\"><title>1704565765000-&gt;1704566174856</title>\n<path d=\"M149.5,-83.3664C149.5,-75.1516 149.5,-65.6579 149.5,-56.7252\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"153,-56.6068 149.5,-46.6068 146,-56.6069 153,-56.6068\" stroke=\"black\"/>\n</g>\n</g>\n</svg>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "network = models.Sequential()\n",
    "\n",
    "# 렐루 활성화 모델 FC 추가\n",
    "network.add(layers.Dense(units=16, activation='relu', input_shape=(10,)))\n",
    "\n",
    "# 또 추가\n",
    "network.add(layers.Dense(units=16, activation='relu'))\n",
    "\n",
    "# 시그모이드 활성화 함수를 사용한 완전 연결층(출력층) 추가\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# 신경망 구조 그리기\n",
    "SVG(model_to_dot(network, show_shapes=True).create(prog=\"dot\", format=\"svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# 신경망 구조를 시각화한 그림을 파일로 저장\n",
    "plot_model(network, show_shapes=True, to_file='network.png')"
   ]
  },
  {
   "source": [
    "* 신경망을 빠르게 시각화 가능한 유틸리티 함수 제공\n",
    "    * 주피터 노트북에 그리고 싶다면, model_to_dot 함수로 가능하다.\n",
    "    * show_shapes 파라미터로 입력과 출력의 크기를 보여주어 디버깅에 도움이 된다.\n",
    "    * 간단한 모델은 show_shapes=True로 지정해볼 수 있다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ],
      "image/svg+xml": "<svg height=\"352pt\" viewBox=\"0.00 0.00 174.00 264.00\" width=\"232pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.33333 1.33333) rotate(0) translate(4 260)\">\n<title>G</title>\n<polygon fill=\"white\" points=\"-4,4 -4,-260 170,-260 170,4 -4,4\" stroke=\"none\"/>\n<!-- 1704565767688 -->\n<g class=\"node\" id=\"node1\"><title>1704565767688</title>\n<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 166,-255.5 166,-219.5 0,-219.5\" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-233.8\">dense_1_input: InputLayer</text>\n</g>\n<!-- 1704408669640 -->\n<g class=\"node\" id=\"node2\"><title>1704408669640</title>\n<polygon fill=\"none\" points=\"31,-146.5 31,-182.5 135,-182.5 135,-146.5 31,-146.5\" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-160.8\">dense_1: Dense</text>\n</g>\n<!-- 1704565767688&#45;&gt;1704408669640 -->\n<g class=\"edge\" id=\"edge1\"><title>1704565767688-&gt;1704408669640</title>\n<path d=\"M83,-219.313C83,-211.289 83,-201.547 83,-192.569\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"86.5001,-192.529 83,-182.529 79.5001,-192.529 86.5001,-192.529\" stroke=\"black\"/>\n</g>\n<!-- 1704565765000 -->\n<g class=\"node\" id=\"node3\"><title>1704565765000</title>\n<polygon fill=\"none\" points=\"31,-73.5 31,-109.5 135,-109.5 135,-73.5 31,-73.5\" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-87.8\">dense_2: Dense</text>\n</g>\n<!-- 1704408669640&#45;&gt;1704565765000 -->\n<g class=\"edge\" id=\"edge2\"><title>1704408669640-&gt;1704565765000</title>\n<path d=\"M83,-146.313C83,-138.289 83,-128.547 83,-119.569\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"86.5001,-119.529 83,-109.529 79.5001,-119.529 86.5001,-119.529\" stroke=\"black\"/>\n</g>\n<!-- 1704566174856 -->\n<g class=\"node\" id=\"node4\"><title>1704566174856</title>\n<polygon fill=\"none\" points=\"31,-0.5 31,-36.5 135,-36.5 135,-0.5 31,-0.5\" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-14.8\">dense_3: Dense</text>\n</g>\n<!-- 1704565765000&#45;&gt;1704566174856 -->\n<g class=\"edge\" id=\"edge3\"><title>1704565765000-&gt;1704566174856</title>\n<path d=\"M83,-73.3129C83,-65.2895 83,-55.5475 83,-46.5691\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"86.5001,-46.5288 83,-36.5288 79.5001,-46.5289 86.5001,-46.5288\" stroke=\"black\"/>\n</g>\n</g>\n</svg>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# 신경망 구조 그리기\n",
    "SVG(model_to_dot(network, show_shapes=False).create(prog=\"dot\", format=\"svg\"))"
   ]
  },
  {
   "source": [
    "## 20.15 이미지 분류하기\n",
    "* 합성곱 신경망으로 이미지를 분류하고 싶다. 케라스에서 가능하다.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gurdk\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\gurdk\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x18c96a17188>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "# 컬러 채널이 처음에 오도록 설정한다.\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "# 랜덤 시드 저장\n",
    "np.random.seed(0)\n",
    "\n",
    "# 이미지 정보 설정\n",
    "channels = 1\n",
    "height = 28\n",
    "width = 28\n",
    "\n",
    "# MNIST 데이터에서 훈련 데이터와 타깃 데이터를 로드합니다.\n",
    "(data_train, target_train), (data_test, target_test) = mnist.load_data()\n",
    "\n",
    "# 훈련 이미지 데이터를 특성의 크기로 변경\n",
    "data_train = data_train.reshape(data_train.shape[0], channels, height, width)\n",
    "\n",
    "# 테스트 이미지 데이터를 특성의 크기로 변경\n",
    "data_test = data_test.reshape(data_test.shape[0], channels, height, width)\n",
    "\n",
    "# 0과 1 사이로 픽셀 강도의 스케일 조정\n",
    "features_train = data_train / 255\n",
    "features_test = data_test / 255\n",
    "\n",
    "# 타깃 데이터를 원핫 인코딩한다.\n",
    "target_train = np_utils.to_categorical(target_train)\n",
    "target_test = np_utils.to_categorical(target_test)\n",
    "number_of_classes = target_test.shape[1]\n",
    "\n",
    "# 신경망 모델 제작\n",
    "network = Sequential()\n",
    "\n",
    "# 64 필터, 5곱하기 5 윈도, 렐루 활성화 함수 FC 층 추가\n",
    "network.add(Conv2D(filters=64, kernel_size=(5, 5),input_shape=(channels, width, height), activation='relu'))\n",
    "\n",
    "# 2*2 윈도 사용하는 최대 풀링층 추가\n",
    "network.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 드롭아웃 추가\n",
    "network.add(Dropout(0.5))\n",
    "\n",
    "# 입력을 일렬로 펼치는 층을 추가\n",
    "network.add(Flatten())\n",
    "\n",
    "# 렐루 활성화 함수를 사용한 128개 유닛의 FC 추가\n",
    "network.add(Dense(units=128, activation=\"relu\"))\n",
    "\n",
    "# 드롭아웃\n",
    "network.add(Dropout(0.5))\n",
    "\n",
    "# 소프트맥스 활성화 FC\n",
    "network.add(Dense(number_of_classes, activation=\"softmax\"))\n",
    "\n",
    "# 신경망 모델 설정 완료\n",
    "network.compile(loss=\"categorical_crossentropy\",\n",
    "optimizer=\"rmsprop\",\n",
    "metrics=[\"accuracy\"])# 성능 지표\n",
    "\n",
    "# 신경망 훈련\n",
    "network.fit(features_train,\n",
    "target_train,\n",
    "epochs=2,\n",
    "verbose=0,\n",
    "batch_size=1000,\n",
    "validation_data=(features_test, target_test))# 검증 데이터\n"
   ]
  },
  {
   "source": [
    "* 합성곱 신경망(ConvNet) : 컴퓨터 비전 작업에 매우 효과적 증명된 네트워크 종류\n",
    "* 피드포워드 신경망에서 각 픽셀이 특정이 되는 식으로 이미지 처리 가능\n",
    "* 피드 포워드 신경망의 두 가지 문제점\n",
    "\n",
    "1. 피드포워드 신경망이 픽셀의 공간 구조를 다루지 못한다.\n",
    "    * 10*10 픽셀의 이미지가 100 픽셀의 특성 벡터로 변환\n",
    "    * 피드포워드 신경망은 첫 특성(픽셀값)과 10번째 특성 관계가 11번째 특성 관계와 같다.\n",
    "        * 실제로는 10번째 특성이 이미지에서 첫 번째 특성과 멀리 떨어진 픽셀이다. \n",
    "        * 11번째는 첫 번째 픽셀 바로 아래에 있는 픽셀이다.\n",
    "2. 피드포워드 신경망이 지역 패턴 대신 전체적인 특성의 관계를 학습한다.\n",
    "    * 물체가 이미지에 나타나는 위치에 상관없이 감지할 수 없다.\n",
    "    * 이미지는 어느 위치에서든 나타날 수 있다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* 합성곱 신경망이 해결!\n",
    "* 개별 이미지 데이터는 2~3개의 차원을 가진다.(높이,너비,깊이)\n",
    "    * 깊이 차원 : 픽셀의 컬러 기반\n",
    "        * 흑백 이미지는 깊이가 1개이므로 2차원 행렬\n",
    "        * 컬러 이미지는 RGB로 깊이가 2개이므로 3차원 텐서로 생각할 수 있다.\n",
    "    * 너비와 높이, 깊이(특성 맵)에서 세 번째 차원(컬러 값을 가진 차원)은 필터(filter)라 부르는 픽셀이 속한 패턴 나타낸다.\n",
    "* 풀링층(pooling layer) : 데이터 위에서 윈도를 이동(스트라이드 stride)\n",
    "    * 윈도가 겹치지 않게 이동하면서 어떤 방식으로 윈도 값 요약하여 데이터 크기 줄인다.\n",
    "    * 윈도 안에 최댓값을 다음 층으로 보내는 최대 풀링(max pooling)\n",
    "        * 실용적이다. 매우 빠르게 학습할 모델 파라미터를 많이 만든다.\n",
    "        * 최대 풀링은 이미지를 줌 아웃하는 것으로 생각할 수 있다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "network.summary()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 64, 24, 24)        1664      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 64, 12, 12)        0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 64, 12, 12)        0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 9216)              0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 128)               1179776   \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 10)                1290      \n=================================================================\nTotal params: 1,182,730\nTrainable params: 1,182,730\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "source": [
    "* 합성곱층과 완전 연결층에 있는 가중치 개수 비교 가능하다.\n",
    "    * 함성곱층의 가중치 크기 : 입력에 상관없이 필터로 결정\n",
    "        * 5x5 필터 64개 사용하고, 필터마다 한 개의 절편이 필요하므로, 5x5x64+64 = 1664\n",
    "    * 완전 연결층 : 입력크기 * 유닛 개수에 절편을 더하면, 9216*128+128 = 1179176개 입니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 20.16 이미지 증식으로 성능 향상하기\n",
    "\n",
    "* 합성곱 신경망의 성능 향상\n",
    "* 성능 향상은 ImageDataGenerator 클래스로 이미지 전처리하고 데이터 증식"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 12665 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 이미지 증식을 위해 객체를 제작\n",
    "augmentation = ImageDataGenerator(\n",
    "    featurewise_center=True, # ZCA 화이트닝 적용\n",
    "    zoom_range=0.3, # 이미지 랜덤하게 확대\n",
    "    width_shift_range=0.2, # 이미지 랜덤하게 이동\n",
    "    horizontal_flip=True, # 이미지 랜덤하게 뒤집기\n",
    "    rotation_range=90)\n",
    "\n",
    "# 'raw/images' 디렉토리에 있는 모든 이미지에 적용\n",
    "augemnt_images = augmentation.flow_from_directory(\n",
    "    \"raw/images\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    save_to_dir=\"processed/images\")\n",
    "    "
   ]
  },
  {
   "source": [
    "* 합성곱 신경망 성능 향상 방법 : 이미지 전처리\n",
    "    * 기본 전처리  포함한 케라스의 ImageDataGenerator 클래스 소개\n",
    "    * 해결에 feature_wise_center = True : 전체 데이터에 걸쳐 픽셀값 표준화\n",
    "* 잡음 추가\n",
    "    * 데이터에 잡음이 추가될 때 신경망의 성능이 향상된다.\n",
    "    * 잡음을 만났을 때 안정적이고 과적합을 막아준다.\n",
    "        * 여러 방식으로 이미지를 랜덤 변환하여 샘플에 잡음 추가 가능하다.\n",
    "            * 이미지 뒤집거나 확대하는 식이다.\n",
    "            * 조금만 변경해도 모델의 성능을 크게 향상시킬 수 있다.\n",
    "            * ImageDataGenerator 클래스로 어떤 변환이든 가능하다. 케라스 문서 참고한다.\n",
    "                * 랜덤 확대, 이동, 반전, 회전 등 일부 변환 적용\n",
    "                "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* flow_from_directory 메서드 출력 : 파이썬 제너레이터 객체\n",
    "    * 대부분 훈련을 위해 신경망에 이미지 보낼 때 처리하는 것을 선호한다.\n",
    "    * 훈련 전 모든 이미지를 처리하고 싶다면 이 제너레이터(flow_from_directory)를 반복하면 된다.\n",
    "\n",
    "            network.fit_generator(augment_images,\n",
    "                                steps_per_epoch=2000, # 에폭마다 제너레이터를 호출할 횟수\n",
    "                                epochs=5, # 에폭 횟수\n",
    "                                validation_data=augemnt_images_test, # 테스트 데이터 제너레이터\n",
    "                                validation_steps=800) # 테스트 에폭마다 제너레이터 호출 횟수"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 20.17 텍스트 분류하기\n",
    "* LSTM(Long Short-Term Memory) 순환 신경망을 사용한다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gurdk\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(0)\n",
    "\n",
    "# 필요한 특성 개수 지정\n",
    "number_of_features = 1000\n",
    "\n",
    "# 영화 리뷰 데이터에서 훈련 데이터와 타깃 벡터 로드\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "    num_words=number_of_features)\n",
    "\n",
    "# 각 샘플이 400개의 특성을 가지도록 패딩하거나 잘라낸다\n",
    "features_train = sequence.pad_sequences(data_train, maxlen=400)\n",
    "features_test = sequence.pad_sequences(data_test, maxlen=400)\n",
    "\n",
    "# 신경망 모델 제작\n",
    "network = models.Sequential()\n",
    "\n",
    "# 임베딩(embedding) 층을 추가합니다.\n",
    "network.add(layers.Embedding(input_dim=number_of_features, output_dim=128))\n",
    "\n",
    "# 128개의 유닛을 가진 LSTM 층을 추가\n",
    "network.add(layers.LSTM(units=128))\n",
    "\n",
    "# 시그모이드 활성화 함수를 사용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# 신경망 모델 설정 완료\n",
    "network.compile(loss=\"binary_crossentropy\",\n",
    "optimizer=\"Adam\",\n",
    "metrics=[\"accuracy\"])\n",
    "\n",
    "# 신경망 훈련\n",
    "history = network.fit(features_train,\n",
    "                        target_train,\n",
    "                        epochs=3,\n",
    "                        verbose=0,\n",
    "                        batch_size=1000,\n",
    "                        validation_data=(features_test, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "# 처음 샘플을 확인한다.\n",
    "print(data_train[0])"
   ]
  },
  {
   "source": [
    "* 리스트의 각 정수는 특정 하나의 단어에 대응된다.\n",
    "    * 리뷰마다 단어의 개수가 다르므로, 샘플 길이가 모두 같지 않다.\n",
    "    * 그래서 신경망에 입력으로 사용하기 전, 동일 길이로 맞춘다.\n",
    "    * pad_sequences 함수 : 샘플 데이터에 패딩 추가하여 동일 길이로 맞춘다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   1 591 202  14  31   6 717  10  10   2\n   2   5   4 360   7   4 177   2 394 354   4 123   9   2   2   2  10  10\n  13  92 124  89 488   2 100  28   2  14  31  23  27   2  29 220 468   8\n 124  14 286 170   8 157  46   5  27 239  16 179   2  38  32  25   2 451\n 202  14   6 717]\n"
     ]
    }
   ],
   "source": [
    "# 처음 샘플 확인\n",
    "print(features_test[0])"
   ]
  },
  {
   "source": [
    "* 자연어 처리에서 가장 촉망되는 단어 임베딩(word embedding) 사용\n",
    "    * 각 단어를 다차원 공간상의 하나의 벡터로 표현한다.\n",
    "        * 두 벡터 사이의 거리로 단어 간의 유사도 표현 가능\n",
    "            * 케라스의 Embedding 층을 추가\n",
    "            * 임베딩 층에 값이 입력되면, 그 단어를 표현하는 벡터 출력\n",
    "    * 128개의 유닛을 가진 LSTM 층이 앞의 입력에서 얻은 정보를 미래에 사용하도록 만든다.\n",
    "        * 따라서 순차적인 데이터 처리가 가능하다.\n",
    "* 이진 분류 문제이므로 하나의 유닛 + 시그모이드 활성화 함수를 사용한 완전 연결된 출력층 추가"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* 케라스 LSTM 외에 GRU(Gated Recurrent Unit) 층을 위한 클래스 제공한다. LSTM 클래스를 GRU로 바꾸면 된다. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "\n",
    "network.add(layers.Embedding(input_dim=number_of_features, output_dim=128))\n",
    "\n",
    "# GRU 128개 유닛 층 추가\n",
    "network.add(layers.GRU(units=128))\n",
    "\n",
    "# 시그모이드 출력층 추가\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# 신경망 모델의 설정 완료\n",
    "network.compile(loss=\"binary_crossentropy\",\n",
    "optimizer=\"Adam\",\n",
    "metrics=[\"accuracy\"])\n",
    "\n",
    "# 신경망 훈련\n",
    "history = network.fit(features_train,\n",
    "                        target_train,\n",
    "                        epochs=3,\n",
    "                        verbose=0,\n",
    "                        batch_size=1000,\n",
    "                        validation_data=(features_test, target_test)) # 테스트 데이터"
   ]
  }
 ]
}