{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit (conda)",
   "display_name": "Python 3.7.6 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "be616a5aca28d3db9b0a9b4d7f249131c3d6f9e1a336d502c86d6e4c207752b0"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Chapter 20. 신경망"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 20.0 소개\n",
    "* 신경망의 핵심은 유닛(노드, 뉴런) 이다.\n",
    "    * 유닛 : 하나 이상의 입력을 받아 각 입력에 파라미터(가중치)를 곱한다.\n",
    "    * 가중치가 곱해진 입력에 어떤 bias 값(0)을 더하고 활성화 함수에 이를 전달한다.\n",
    "    * 출력은 신경망에서 만약 있다면 더 깊은 층에 있는 다른 뉴런을 위해 앞으로 전달한다.\n",
    "* 피드포워드 신경망 혹은 다층 퍼셉트론 : 다양한 실전 환경에서 사용되는 가장 간단한 인공 신경망이다.\n",
    "    * 신경망이 일련의 연결된 층으로 표현할 수 있고, 한쪽 끝에는 샘플의 특성값과 다른 한쪽에는 타깃값을 연결한 네트워크 이다.\n",
    "    * 피드포워드 : 샘플의 특성값이 네트워크 앞쪽으로 주입된다는 사실에서 착안한다.\n",
    "    * 각 층은 연속적으로 특성값을 변환하여 타깃값과 같은 최종 출력을 내는 게 목적이다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* 피드 포워드 신경망 : 입력층(input layer), 출력층(output layer), 은닉층(hidden layer)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 20.1 신경망을 위한 데이터 전처리하기\n",
    "* StandardScaler로 특성을 표준화한다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-1.12541308,  1.96429418],\n",
       "       [-1.15329466, -0.50068741],\n",
       "       [ 0.29529406, -0.22809346],\n",
       "       [ 0.57385917, -0.42335076],\n",
       "       [ 1.40955451, -0.81216255]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "features = np.array([[-100.1, 3240.1],\n",
    "                    [-200.2, -234.1],\n",
    "                    [5000.5, 150.1],\n",
    "                    [6000.6, -125.1],\n",
    "                    [9000.9, -673.1]])\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# 특성 변환\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# 특성 확인\n",
    "features_standardized"
   ]
  },
  {
   "source": [
    "* 신경망의 모델 파라미터는 작은 난수로 초기화한다.\n",
    "    * 특성값이 모델 파라미터보다 크면 종종 신경망의 성능이 나빠진다.\n",
    "    * 샘플의 특성값이 개별 유닛을 통과하면서 합쳐지므로, 모든 특성은 같은 스케일을 가져야 한다.\n",
    "    * 그래서 각 특성을 모두 평균이 0이고 표준편차 1이되도록 표준화하는 게 가장 좋다.(필수 아니고, 이진 특성인 경우 예외)\n",
    "    "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "평균: 0.0\n표준편차: 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "print(\"평균:\", round(features_standardized[:, 0].mean()))\n",
    "print(\"표준편차:\", features_standardized[:, 0].std())"
   ]
  },
  {
   "source": [
    "## 20.2 신경망 구성하기\n",
    "* 케라스의 Sequential 모델 활용"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# 신경망 모델을 만든다.\n",
    "network = models.Sequential()\n",
    "\n",
    "# 렐루 활성화 함수를 사용한 완전 연결층을 추가한다.\n",
    "network.add(layers.Dense(units=16, activation=\"relu\", input_shape=(10, )))\n",
    "\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# 시그모이드 활성화 함수를 사용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# 신경망의 모델 설정 완료\n",
    "network.compile(loss=\"binary_crossentropy\", # 크로스 엔트로피\n",
    "optimizer=\"rmsprop\", # 옵티마이저\n",
    "metrics=[\"accuracy\"]) # 정확도를 성능 지표로 한다.\n"
   ]
  },
  {
   "source": [
    "* 자주 쓰는 조합 확인\n",
    "    * 이진 분류 : 시그모이드 함수와 하나의 유닛\n",
    "    * 다중 분류 : 소프트맥스 활성화 함수와 k 개의 유닛(k : 타깃 클래스의 개수)\n",
    "    * 회귀 : No 활성화 함수\n",
    "* 손실 함수 정의(예측값이 타깃값과 얼마나 잘 맞는지 측정 함수)\n",
    "    * 이진 분류 : 이진 크로스 엔트로피\n",
    "    * 다중 분류 : 범주형 크로스 엔트로피\n",
    "    * 회귀 : 평균 제곱 오차"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* 옵티 마이저 정의 : 가장 작은 손실 함수 오차를 만드는 모델 파라미터 값 찾기\n",
    "    * 확률적 경사 하강법, 모멘텀(momentum)\n",
    "    * RMSProp(Root Mean Square Propagation), Adam(Adaptive Moment estimation)\n",
    "* 하나 이상의 성능 지표(정확도 등)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* 신경망 제작 방법 두 가지 : 층을 쌓는 방식, 함수형 API(functional API)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_7 (Dense)              (None, 16)                176       \n_________________________________________________________________\ndense_8 (Dense)              (None, 16)                272       \n_________________________________________________________________\ndense_9 (Dense)              (None, 1)                 17        \n=================================================================\nTotal params: 465\nTrainable params: 465\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "source": [
    "* 첫번째 은닉층 : units=16, activation='relu'\n",
    "    * 렐루 활성화 함수를 가진 16개 유닛 구성\n",
    "    * 케라스에서 네트워크의 첫 번째 은닉층 : input_shape 파라미터 포함해야 한다.\n",
    "    * (10,) : 첫 층이 10개의 특성을 가진 샘플을 기대한다.\n",
    "* 두번째 층 : input_shape 매개변수만 없다. 나머지는 동일하다.\n",
    "* 출력층 : 이진 분류가 목적이므로 시그모이드 활성화 함수 사용한 유닛 하나만 포함한다.\n",
    "* 모델 훈련을 위해 케라스에게 네트워크의 훈련 방법 알려준다.\n",
    "    * compile 메서드 :: 최적화 알고리즘(RMSProp), 손실 함수(binary_crossentropy), 하나 이상의 성능 지표를 지정한다.\n",
    "\n",
    "* 케라스 summary 메서드 : 추가된 층 수와 가중치 개수를 보여준다.\n",
    "    * 첫번째 차원은 배치 차원으로, 모델 구성시 None 으로 설정 된다.\n",
    "    * 160개 가중치 + 16개 절편(bias) = 176개와 일치한다.\n",
    "    * 첫 입력층은 입력값 자체이며 훈련되는 가중치가 없다. 그래서 은닉층 2개와 출력층 1개만 확인할 수 있다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력에서 출력까지 3 개의 완전 연결층을 연결한다.\n",
    "x = layers.Input(shape=(10,))\n",
    "h1 = layers.Dense(units=16, activation=\"relu\")(x)\n",
    "h2 = layers.Dense(units=16, activation=\"relu\")(h1)\n",
    "y = layers.Dense(units=1, activation=\"sigmoid\")(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 모델 제작\n",
    "network = models.Model(x, y)\n",
    "\n",
    "# 신경망 모델 설정 완료\n",
    "network.compile(loss=\"binary_crossentropy\",\n",
    "optimizer=\"rmsprop\",\n",
    "metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 10)                0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 16)                176       \n_________________________________________________________________\ndense_11 (Dense)             (None, 16)                272       \n_________________________________________________________________\ndense_12 (Dense)             (None, 1)                 17        \n=================================================================\nTotal params: 465\nTrainable params: 465\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "source": [
    "* Dense 클래스의 객체 생성 부분 + 입력값 주입 부분 나누어 쓰면 더 쉽게 이해할 수 있다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = layers.Dense(units=16, activation=\"relu\")\n",
    "h1 = dense(x)"
   ]
  },
  {
   "source": [
    "* 파이썬 객체 호출시 특수 메서드 __call__ 실행\n",
    "    * Dense 층의 정방향 계산(forward propagation) 수행"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 20.3 이진 분류기 훈련하기\n",
    "* 케라스 사용해서 피드포워드 신경망 만들고 fit 메서드로 훈련"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gurdk\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 0s 18us/step - loss: 0.4195 - accuracy: 0.8120 - val_loss: 0.3394 - val_accuracy: 0.8546\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 0s 14us/step - loss: 0.3225 - accuracy: 0.8641 - val_loss: 0.3284 - val_accuracy: 0.8594\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 0s 14us/step - loss: 0.3107 - accuracy: 0.8691 - val_loss: 0.3392 - val_accuracy: 0.8537\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(0)\n",
    "\n",
    "# 필요한 특성 개수를 지정한다.\n",
    "number_of_features = 1000\n",
    "\n",
    "# 영화 리뷰 데이터에서 훈련 데이터와 타깃 벡터 로드\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "    num_words=number_of_features\n",
    ")\n",
    "\n",
    "# 영화 리뷰 데이터를 원-핫 인코딩된 특성 행렬로 변환\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "\n",
    "# 신경망 모델 제작\n",
    "network = models.Sequential()\n",
    "\n",
    "# 렐루 활성화 함수를 이용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=16, activation=\"relu\", input_shape=(number_of_features,)))\n",
    "\n",
    "# 렐루 활성화 함수를 이용한 완전 연결층\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# 시그모이드 활성화 함수를 사용한 완전 연결층 추가\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# 신경망의 모델 설정 완료\n",
    "network.compile(loss=\"binary_crossentropy\", # 손실 함수 : 이진 크로스엔트로피\n",
    "optimizer=\"rmsprop\", # 옵티마이저\n",
    "metrics=[\"accuracy\"]) # 성능 지표\n",
    "\n",
    "# 신경망 훈련\n",
    "history = network.fit(features_train, # 특성\n",
    "target_train,\n",
    "epochs=3, # 에폭 횟수\n",
    "verbose=1, # 에폭 과정을 출력\n",
    "batch_size = 100, # 배치의 샘플 개수\n",
    "validation_data=(features_test, target_test) # 테스트 데이터\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(25000, 1000)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# 특성 행렬의 크기 확인\n",
    "\n",
    "features_train.shape"
   ]
  },
  {
   "source": [
    "* epochs : 훈련할 때 사용할 에폭 횟수 정의\n",
    "* verbose : 훈련 과정 동안 얼마나 많은 정보 출력할지 결정한다.\n",
    "    * verbose = 0 : 출력 없음\n",
    "    * verbose=1 : 진행 막대 출력\n",
    "    * verbose=2 : 에폭당 한 줄씩 로그 출력\n",
    "* batch_size : 모델 파라미터 업데이트 전에 네트워크 통과시킬 샘플 개수 설정\n",
    "* 모델 평가 위해 사용할 테스트 세트 보관 : validation_data 변수 활용 혹은 validation_split 파라미터로 평가에 사용할 비율 사전 정의 가능하다.\n",
    "* 케라스의 fit : 에폭마다 손실값 + 성능 수치 담긴 History 객체 반환(사이킷런은 훈련 모델을 반환)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 1s 20us/step - loss: 0.3025 - val_loss: 0.3257\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 0s 14us/step - loss: 0.2933 - val_loss: 0.3304\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 0s 14us/step - loss: 0.2819 - val_loss: 0.3268\n"
     ]
    }
   ],
   "source": [
    "# 신경망의 모델 설정 완료\n",
    "network.compile(loss=\"binary_crossentropy\",\n",
    "optimizer = \"rmsprop\")\n",
    "\n",
    "# 신경망 훈련한다.\n",
    "history = network.fit(features_train,\n",
    "target_train,\n",
    "epochs=3,\n",
    "verbose=1,\n",
    "batch_size=100,\n",
    "validation_data = (features_test, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "25000/25000 [==============================] - 0s 10us/step\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.3267870804977417"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "network.evaluate(features_test, target_test)"
   ]
  },
  {
   "source": [
    "* 케라스 내 IMDB 데이터 : 텍스트를 정수의 리스트로 변환한 것이다.\n",
    "    * Tokenizer 클래스"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}