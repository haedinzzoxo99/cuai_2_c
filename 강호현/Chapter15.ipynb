{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.2 64-bit ('python3': conda)",
   "display_name": "Python 3.7.2 64-bit ('python3': conda)",
   "metadata": {
    "interpreter": {
     "hash": "9afdf4d233adf410414f65d6b1593c2d6233a3bcdbeac0283ac83f599002f4da"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Chapter 15. K-Nearest Neighbors\n",
    "\n",
    "## 15.0 Introduction\n",
    "* KNN : one of the simplest yet most commonly used classifiers in supervised ML."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 15.1 Finding an Observation's Nearest Neighbors\n",
    "\n",
    "* Find an obs's k nearest observations(Neighbors)\n",
    "* scikit-learn's NearestNeighbors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[1.03800476, 0.55861082, 1.10378283, 1.18556721],\n",
       "        [0.79566902, 0.32841405, 0.76275827, 1.05393502]]])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# Standardize features\n",
    "features_standardized = standardizer.fit_transform(features)\n",
    "\n",
    "# Two nearest neighbors\n",
    "nearest_neighbors = NearestNeighbors(n_neighbors=2).fit(features_standardized)\n",
    "\n",
    "# Create an observation\n",
    "new_observation = [ 1, 1, 1, 1]\n",
    "\n",
    "# Find distances and indices of the observation's NN.\n",
    "distances, indices = nearest_neighbors.kneighbors([new_observation])\n",
    "\n",
    "# View the NN\n",
    "features_standardized[indices]"
   ]
  },
  {
   "source": [
    "$$d_{euclidean} = \\sqrt{\\sum_{i=1}^n (x_i - y_i)^2}$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* NearestNeighbors : Minkowski 거리를 사용한다.\n",
    "    * 조정하기 위해서는 metric 파라미터를 활용한다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Find each obs's three nearest neighbors\n",
    "# 유클리드 거리 기반으로 찾아 본다.\n",
    "\n",
    "nearestneighbors_euclidean = NearestNeighbors(\n",
    "    n_neighbors=3, metric=\"euclidean\").fit(features_standardized)\n",
    "\n",
    "# List of lists indicating each obs's 3 NNs\n",
    "nearest_neighbors_with_self = nearestneighbors_euclidean.kneighbors_graph(\n",
    "    features_standardized).toarray()\n",
    "\n",
    "# 관측값을 1로 마킹된 것을 제거한다.\n",
    "for i, x in enumerate(nearest_neighbors_with_self):\n",
    "    x[i] = 0\n",
    "\n",
    "# Vuew first obs's two nearest neighbors\n",
    "nearest_neighbors_with_self[0]"
   ]
  },
  {
   "source": [
    "## 15.2 Creating a K-Nearest Neighbor Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* 데이터셋이 매우 크지 않으면, KNeighborsClassifier 활용한다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# 피처를 표준화 한다.\n",
    "X_std = standardizer.fit_transform(X)\n",
    "\n",
    "# KNN classifiers with 5 neighbors로 훈련한다.\n",
    "knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1).fit(X_std, y)\n",
    "\n",
    "# 2 obs 제작\n",
    "new_observations = [[0.75, 0.75, 0.75, 0.75], [1,1,1,1]]\n",
    "\n",
    "# Predict the class of two obs\n",
    "knn.predict(new_observations)"
   ]
  },
  {
   "source": [
    "* KNeighborsClassifier의 파라미터\n",
    "    * metric : 거리 기준을 결정한다.\n",
    "    * n_jobs : 컴퓨터 코어 수를 결정한다.\n",
    "    * algorithm : NN을 계산하는 방법을 결정한다.\n",
    "        * 물론 알고리즘은 이 분류기가 결정한다.(디폴트)\n",
    "    * 각 이웃은 하나의 보트를 수행하고, 다만 weights로 거리가 설정된다면, 더 가까운 관측값의 보트가 더 가중치를 갖는다.\n",
    "    * 더 비슷한 이웃이 더 많이 클래스를 말해주기 때문이다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 15.3 Identifying the Best Neighborhood Size\n",
    "\n",
    "* Best value for k in a KNN Classifier.\n",
    "* GridSearchCV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# Create standardizer\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# Create a KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "\n",
    "# Create a pipeline\n",
    "pipe = Pipeline([(\"standardizer\", standardizer), (\"knn\", knn)])\n",
    "\n",
    "# Create space of candidate values : Dict 타입으로, 표기명에 주의한다.\n",
    "search_space = [{\"knn__n_neighbors\": [1,2,3,4,5,6,7,8,9,10]}]\n",
    "\n",
    "# Grid search\n",
    "classifier = GridSearchCV(\n",
    "    pipe, search_space, cv=5, verbose=0).fit(features_standardized, target)"
   ]
  },
  {
   "source": [
    "* k의 크기는 KNN classifiers에 큰 의미를 가진다.\n",
    "* ML에서 우리는 bias, variance 사이에 균형을 찾고자 하고, k의 값이 명확하지 않다.\n",
    "* 이 때, Grid search 를 통해서 여러 k 값으로 교차 검증을 해볼 수 있다.(5-fold cv)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Best neighborhood size (k)\n",
    "classifier.best_estimator_.get_params()[\"knn__n_neighbors\"]"
   ]
  },
  {
   "source": [
    "## 15.4 Creating a Radius-Based Nearest Neighbor Classifier\n",
    "\n",
    "* unknown class를 갖는 관측값에서, 일정한 거리 기반으로 모든 관측값의 클래스를 예측하고 싶다.\n",
    "* 거리가 나오면, Radius를 생각한다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# RadiusNeighborsClassifier\n",
    "\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# Create standardizer\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# Standardize features\n",
    "features_standardized = standardizer.fit_transform(features)\n",
    "\n",
    "# 이제, 방사 이웃 분류기를 훈련 시킨다. 줄이면 rnn이라 한다.\n",
    "rnn = RadiusNeighborsClassifier(\n",
    "    radius=.5, n_jobs=-1).fit(features_standardized, target)\n",
    "\n",
    "# 2 obs\n",
    "new_observations = [[1, 1, 1, 1]]\n",
    "\n",
    "# Predict the class of 2 obs\n",
    "rnn.predict(new_observations)"
   ]
  },
  {
   "source": [
    "* KNN classification\n",
    "    * k개 이웃들의 클래스에서 예측된다.\n",
    "* radius-based (RNN) classifier : 주어진 radius r 내에 모든 관측값의 클래스를 예측한다.\n",
    "    * 사이킷 런에서 제공하고 있고, 2가지 파라미터가 차이가 있다.(KNN 비교)\n",
    "        * radius를 지정해야 한다.\n",
    "        * outlier_label : no obs인 경우 관측값에 주어지는 라벨이다. 이상치(outlier) 탐색에 유용하다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}