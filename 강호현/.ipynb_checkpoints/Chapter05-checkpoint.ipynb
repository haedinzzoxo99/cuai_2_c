{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5. 범주형 데이터 다루기\n",
    "## 5.0 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 관측 대상을 양이 아니라 질로 측정하는 게 유용할 수 있다.\n",
    "* 종류\n",
    "    * 명목형 범주(nominal) : 순서가 없는 범주\n",
    "    * 순서형 범주(ordinal) : 자연적인 순서를 가진다.\n",
    "* 벡터나 문자열의 열로 표현된다.\n",
    "    * 머신러닝은 수치값을 입력해야 하므로 문제가 된다.\n",
    "    \n",
    "* K-최근접 이웃 알고리즘 : 유클리드 거리 사용\n",
    "\n",
    "$$\\sqrt{\\sum_{i=1}^n{(x_i-y_i)^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 순서가 없는 범주형 특성 인코딩하기\n",
    "* 사이킷런의 LabelBinarizer : 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n",
    "\n",
    "feature = np.array([[\"Texas\"],\n",
    "                   [\"California\"],\n",
    "                   [\"Texas\"],\n",
    "                   [\"Delaware\"],\n",
    "                   [\"Texas\"]])\n",
    "\n",
    "one_hot = LabelBinarizer()\n",
    "\n",
    "# 특성을 원핫 인코딩합니다.\n",
    "one_hot.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['California', 'Delaware', 'Texas'], dtype='<U10')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 확인\n",
    "one_hot.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Texas', 'California', 'Texas', 'Delaware', 'Texas'], dtype='<U10')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot.inverse_transform(one_hot.transform(feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 판다스로 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gurdk\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>California</th>\n",
       "      <th>Delaware</th>\n",
       "      <th>Texas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   California  Delaware  Texas\n",
       "0           0         0      1\n",
       "1           1         0      0\n",
       "2           0         0      1\n",
       "3           0         1      0\n",
       "4           0         0      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.get_dummies(feature[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 사이킷런 : 샘플이 여러 개의 클래스를 가지는 경우를 다룰 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1],\n",
       "       [0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 1],\n",
       "       [1, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다중 클래스 특성 제작\n",
    "multiclass_feature = [(\"텍사스\",\"플로리다\"),\n",
    "                      (\"캘리포니아\",\"알바마\"),\n",
    "                      (\"텍사스\",\"플로리다\"),\n",
    "                      (\"델라웨어\",\"플로리다\"),\n",
    "                      (\"텍사스\",\"알바마\")]\n",
    "\n",
    "one_hot_multiclass = MultiLabelBinarizer()\n",
    "\n",
    "one_hot_multiclass.fit_transform(multiclass_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['델라웨어', '알바마', '캘리포니아', '텍사스', '플로리다'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_multiclass.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 하나의 수치값에 각 클래스 할당하게 되면 순서가 개입한다.\n",
    "* 올바른 방법\n",
    "    * 원본 특성인 클래스마다 이진 특성을 하나씩 제작 : 원-핫 인코딩 혹은 더미 인코딩(dummy encoding)\n",
    "    * 원-핫 인코딩 후 선형 의존성을 피하고자 결과 행렬에서 **원-핫 인코딩된 특성 중 하나를 삭제**하는 게 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LabelEncoder : 문자열 타깃 데이터를 정수 레이블로 변환(일차원 배열)\n",
    "* OneHotEncoder(>0.20) : 정수형 특성만 원-핫 인코딩하다가 문자열 데이터도 인식 가능하다.\n",
    "   * 특성 배열을 원-핫 인코딩할 때는 이 클래스를 사용하는 게 좋다.\n",
    "   * 희소 배열을 반환한다. sparse=False 하면 Dense 배열 얻는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 1., 0.],\n",
       "       [1., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 1., 0.],\n",
       "       [0., 0., 1., 1., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 여러 열이 있는 특성 배열(이차원 이상)\n",
    "feature = np.array([[\"Texas\",1],\n",
    "                   [\"California\",1],\n",
    "                   [\"Texas\",3],\n",
    "                   [\"Delaware\",1],\n",
    "                   [\"Texas\",1]])\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "one_hot_encoder.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['California', 'Delaware', 'Texas'], dtype='<U10'),\n",
       " array(['1', '3'], dtype='<U10')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 처음 세 개의 열에 원-핫 인코딩, 나머지 1과 3도 두 개의 열에 원핫인코딩\n",
    "# 클래스 확인 : categories_\n",
    "one_hot_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* OneHotEncoder : 모든 입력 특성 배열을 범주형 인식하여 변환\n",
    "* **ColumnTransformer**와 함께 사용하여, 특정 열에만 적용할 수 있다.(4장)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 순서가 있는 범주형 특성 인코딩하기\n",
    "* 판다스 데이터프레임 replace 메서드 : 문자열 레이블을 수치값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    3\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.DataFrame({\"Score\": [\"Low\",\"Low\",\"Medium\",\"Medium\",\"High\"]})\n",
    "\n",
    "scale_mapper = {\"Low\":1,\n",
    "               \"Medium\":2,\n",
    "               \"High\":3}\n",
    "\n",
    "dataframe[\"Score\"].replace(scale_mapperpper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 리커트 척도 : 특성 클래스에 어떤 순서가 포함된 경우가 있다.\n",
    "* 반드시 클래스 내재된 순서 정보에 기반하여 수치값을 택한다.\n",
    "    * 주로 딕셔너리를 활용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    4\n",
       "5    3\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame({\"Score\": [\"Low\",\n",
    "                                   \"Low\",\n",
    "                                   \"Medium\",\n",
    "                                   \"Medium\",\n",
    "                                   \"High\",\n",
    "                                   \"Barely More Than Medium\"]})\n",
    "\n",
    "scale_mapper = {\"Low\":1,\n",
    "                \"Medium\":2,\n",
    "                \"Barely More Than Medium\":3,\n",
    "                \"High\":4}\n",
    "\n",
    "dataframe[\"Score\"].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "2    2.0\n",
       "3    2.0\n",
       "4    3.0\n",
       "5    2.1\n",
       "Name: Score, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 간격이 일정하지 않은 경우\n",
    "# 클래스 매핑하는 수치값에 주의를 기울인다.\n",
    "\n",
    "scale_mapper = {\"Low\":1,\n",
    "                \"Medium\":2,\n",
    "                \"Barely More Than Medium\":2.1,\n",
    "                \"High\":3}\n",
    "\n",
    "dataframe[\"Score\"].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* OrdinalEncoder 추가(>0.20) : 클래스 범주를 순서대로 변환한다. 정수 데이터도 범주형으로 인식하여 변환\n",
    "    * 특정 열만 범주형으로 변환하려면 ColumnTransformer와 함께 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "features = np.array([[\"Low\",10],\n",
    "                    [\"High\", 50],\n",
    "                    [\"Medium\", 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 2.],\n",
       "       [2., 1.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_encoder = OrdinalEncoder()\n",
    "ordinal_encoder.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['High', 'Low', 'Medium'], dtype='<U6'),\n",
       " array(['10', '3', '50'], dtype='<U6')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 카테고리\n",
    "ordinal_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 특정 딕셔너리를 인코딩하기\n",
    "* DictVectorizer : 딕셔너리를 특성 행렬로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "data_dict = [{\"red\":2, \"blue\":4},\n",
    "            {\"red\":4, \"blue\":3},\n",
    "            {\"red\":1, \"yellow\":2}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictvectorizer = DictVectorizer(sparse=False) # Dense 배열 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dictvectorizer.fit_transform(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 2., 0.],\n",
       "       [3., 4., 0.],\n",
       "       [0., 1., 2.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DictVectorizer : 0이 아닌 값의 원소만 저장하는 희소 행렬 바환하며, 매우 큰 행렬을 다룰 때 도움이 된다.\n",
    "    * 메모리 사용량 최소화\n",
    "    * DictVectorizer + sparse=False : 밀집 벡터 출력 가능(0까지 다 넣기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blue', 'red', 'yellow']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 생성된 특성 이름 : get_feature_naems\n",
    "feature_names = dictvectorizer.get_feature_names()\n",
    "\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>red</th>\n",
       "      <th>yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blue  red  yellow\n",
       "0   4.0  2.0     0.0\n",
       "1   3.0  4.0     0.0\n",
       "2   0.0  1.0     2.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 미려한 출력은 판다ㅣ스 데이터프레임\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(features, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 2., 0.],\n",
       "       [3., 4., 0.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 2., 2.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 네 개의 문서에 대한 단어 카운트 딕셔너리 만든다.\n",
    "doc_1_word_count = {\"red\":2, \"blue\":4}\n",
    "doc_2_word_count = {\"red\":4, \"blue\":3}\n",
    "doc_3_word_count = {\"red\":1, \"yellow\":2}\n",
    "doc_4_word_count = {\"red\":2, \"yellow\":2}\n",
    "\n",
    "# 리스트 제작\n",
    "doc_word_counts = [doc_1_word_count,\n",
    "                  doc_2_word_count,\n",
    "                  doc_3_word_count,\n",
    "                  doc_4_word_count]\n",
    "\n",
    "# 단어 카운트 딕셔너리를 특성 행렬로 변환\n",
    "dictvectorizer.fit_transform(doc_word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 누락된 클래스 값 대체하기\n",
    "* k-최근접 이웃(KNN)분류기 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.31],\n",
       "       [ 1.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 범주형 특성을 가진 특성 행렬 제작\n",
    "X = np.array([[0, 2.10, 1.45],\n",
    "            [1, 1.18, 1.33],\n",
    "            [0, 1.22, 1.27],\n",
    "            [1, -0.21, -1.19]])\n",
    "\n",
    "# 범주형 특성에 결측값이 있는 특성 행렬 제작\n",
    "X_with_nan = np.array([[np.nan, 0.87, 1.31],\n",
    "                      [np.nan, -0.67, -0.22]])\n",
    "\n",
    "clf = KNeighborsClassifier(3, weights='distance')\n",
    "trained_model = clf.fit(X[:, 1:], X[:,0])\n",
    "\n",
    "# 결측값 클래스 예측\n",
    "imputed_values = trained_model.predict(X_with_nan[:, 1:])\n",
    "\n",
    "# 예측 클래스와 원본 특성을 열로 합치기(hstack)\n",
    "X_with_imputed = np.hstack((imputed_values.reshape(-1,1), X_with_nan[:, 1:]))\n",
    "\n",
    "# 두 특성 행렬을 연결한다.\n",
    "np.vstack((X_with_imputed, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  nan,  0.87,  1.31],\n",
       "       [  nan, -0.67, -0.22]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.1 ,  1.45],\n",
       "       [ 1.18,  1.33],\n",
       "       [ 1.22,  1.27],\n",
       "       [-0.21, -1.19]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 1.])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.87,  1.31],\n",
       "       [-0.67, -0.22]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_with_nan[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.31],\n",
       "       [ 0.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이번에는 가장 많이 등장(최빈값)으로 채우기\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X_complete = np.vstack((X_with_nan, X))\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "imputer.fit_transform(X_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 범주형 특성에 결측값\n",
    "    * 머신러닝 알고리즘으로 누락된 값을 예측한다.(베스트)\n",
    "    * 누락 값 특성을 타깃으로 하고 다른 특성을 특성 행렬로 사용한다.\n",
    "    * KNN 가장 맣이 사용한다.\n",
    "        * k 최근접 이웃의 다수 클래스를 누락된 값에 할당한다.\n",
    "    * 대규모 데이터는 최빈값이 좋다.\n",
    "    * 추가로 결측 채운 여부를 나타내는 이진 특성 하나 추가해주면 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 불균형한 클래스 다루기\n",
    "* 타깃 벡터가 매우 불균형 클래스\n",
    "    * 더 많은 데이터 모으기\n",
    "    * 모델 평가 지표 바꾸기\n",
    "        * 모델에 내장된 클래스 가중치 매개변수 사용\n",
    "        * 다운샘플링 혹은 업샘플링 고려"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iris setosa 50개 중 40개 삭제\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "features = iris.data\n",
    "\n",
    "target = iris.target\n",
    "\n",
    "# 40 개 삭제\n",
    "features = features[40:,:]\n",
    "target = target[40:]\n",
    "\n",
    "# 클래스 0을 음성 클래스로 하는 이진 타깃 벡터 제작\n",
    "target = np.where((target == 0), 0, 1)\n",
    "\n",
    "# 불균형한 타깃 벡터 확인\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RandomForestClassifier : class_weight = weights를 딕셔너리로 만들어 넣어볼 수 있습니다.(가중치)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                       class_weight={0: 0.9, 1: 0.1}, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       max_samples=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                       random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomforest class_weight 매개변수\n",
    "weights = {0: .9, 1: 0.1}\n",
    "\n",
    "# 가중치 부여한 랜덤 포레스트 분류기 제작\n",
    "RandomForestClassifier(class_weight=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RandomForestClassifier : class_weight = balanced 지정해서 클래스 빈도에 반비례하게 자동으로 가중치 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 균형잡힌 클래스 가중치로 랜덤 포레스트 모델 훈련한다.\n",
    "RandomForestClassifier(class_weight=\"balanced\") # 반드시 문자로 넣어줘야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 다운샘플링 : 다수 클래스의 샘플 줄이기\n",
    "    * 다수 클래스에서 중복을 허용하지 않고 랜덤 선택하여 소수 클래스 크기로 맞춘다.\n",
    "* 업샘플링 : 소수 클래스 샘플 늘리기\n",
    "    * 소수 클래스에서 중복 허용해서 다수 클래스 크기로 맞춘다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다운 샘플링\n",
    "# 각 클래스의 샘플 인덱스 추출\n",
    "i_class0 = np.where(target == 0)[0]\n",
    "i_class1 = np.where(target == 1)[0]\n",
    "\n",
    "# 각 클래스의 샘플 개수\n",
    "n_class0 = len(i_class0)\n",
    "n_class1 = len(i_class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 100\n"
     ]
    }
   ],
   "source": [
    "print(n_class0, n_class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 0의 샘플만큼 클래스 1에서 중복을 허용하지 않고 랜덤하게 샘플 추출\n",
    "i_class1_downsampled = np.random.choice(i_class1, size=n_class0,\n",
    "                                       replace=False)\n",
    "\n",
    "# 클래스 0 타깃 벡터와 다운샘플링된 클래스 1 타깃 벡터 합치기\n",
    "np.hstack((target[i_class0], target[i_class1_downsampled]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 0의 특성 행렬과 다운샘플링 클래스 1의 특성 행렬 합치기\n",
    "np.vstack((features[i_class0, :], features[i_class1_downsampled, :]))[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 소수 업샘플링\n",
    "# 클래스 1의 샘플 개수만큼 클래스 0에서 중복 허용하여 랜덤하게 샘플을 선택한다.\n",
    "i_class0_upsampled = np.random.choice(i_class0, size = n_class1, replace = True)\n",
    "\n",
    "# 클래스 0 업샘플링 타겟 벡터와 클래스 1의 타깃 벡터 합치기\n",
    "np.concatenate((target[i_class0_upsampled], target[i_class1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.5, 2.3, 1.3, 0.3],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5.1, 3.8, 1.9, 0.4]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 0의 업샘플링된 특성 행렬과 클래스 1의 특성 행렬 합치기\n",
    "np.vstack((features[i_class0_upsampled, :], features[i_class1,:]))[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 실전에는 불균형한 클래스가 아주 많다.\n",
    "    * 소수 클래스의 샘플을 더 많이 모으는 것이 가장 좋다.\n",
    "    * 불균형한 클래스에 잘 맞는 모델 평가 지표를 사용한다.\n",
    "        * 정확도 : 모델 성능 평가에 자주 사용하나, 클래스 불균형할 때는 맞지 않는다.\n",
    "        * 오차 행렬, 정밀도, 재현율, F1 점수, ROC 곡선이 있다.\n",
    "    * 일부 모델에서 제공하는 클래스 가중치 매개변수 사용\n",
    "        * class_weight 매개변수\n",
    "    * 다운샘플링, 업샘플링 : 둘 다 해보고 **더 나은 결과**가 내는 것을 선택한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
